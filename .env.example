# ============================================================================
# Breweries Data Lake - Environment Variables
# ============================================================================
# Copy this file to .env and adjust the values as needed
# DO NOT commit the .env file to the repository (it's in .gitignore)
# ============================================================================

# ----------------------------------------------------------------------------
# Airflow Configuration
# ----------------------------------------------------------------------------

# Docker image name for Airflow
AIRFLOW_IMAGE_NAME=breweries/airflow-delta:3.0.0-python3.11

# User ID for Airflow containers (Linux users should set this to their UID)
# Run: id -u
AIRFLOW_UID=50000

# Base directory for volumes (usually current directory)
AIRFLOW_PROJ_DIR=.

# ----------------------------------------------------------------------------
# Airflow Web UI Credentials
# ----------------------------------------------------------------------------

# Admin username for Airflow web interface
_AIRFLOW_WWW_USER_USERNAME=airflow

# Admin password for Airflow web interface
# CHANGE THIS IN PRODUCTION!
_AIRFLOW_WWW_USER_PASSWORD=airflow

# ----------------------------------------------------------------------------
# Database Configuration
# ----------------------------------------------------------------------------

# PostgreSQL credentials (used by Airflow metadata database)
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow

# ----------------------------------------------------------------------------
# Open Brewery DB API Configuration
# ----------------------------------------------------------------------------

# Base URL for the Open Brewery DB API
BREWERY_API_BASE_URL=https://api.openbrewerydb.org/v1

# API request timeout in seconds
BREWERY_API_TIMEOUT=30

# Number of retries for failed API requests
BREWERY_API_RETRIES=3

# Delay between retries in seconds
BREWERY_API_RETRY_DELAY=5

# ----------------------------------------------------------------------------
# Data Lake Paths
# ----------------------------------------------------------------------------

# Base path for the data lake (inside container)
DATALAKE_BASE_PATH=/opt/airflow/lakehouse

# Bronze layer path (raw data)
BRONZE_PATH=/opt/airflow/lakehouse/bronze

# Silver layer path (curated data)
SILVER_PATH=/opt/airflow/lakehouse/silver

# Gold layer path (aggregated data)
GOLD_PATH=/opt/airflow/lakehouse/gold

# ----------------------------------------------------------------------------
# Spark Configuration
# ----------------------------------------------------------------------------

# Spark application name
SPARK_APP_NAME=Breweries-DataLake

# Number of Spark shuffle partitions
SPARK_SHUFFLE_PARTITIONS=8

# Spark log level (ERROR, WARN, INFO, DEBUG)
SPARK_LOG_LEVEL=ERROR

# ----------------------------------------------------------------------------
# Data Quality Configuration
# ----------------------------------------------------------------------------

# Enable data quality checks (true/false)
ENABLE_DATA_QUALITY_CHECKS=true

# Data quality check level (strict/moderate/lenient)
DATA_QUALITY_LEVEL=strict

# ----------------------------------------------------------------------------
# Monitoring and Alerting
# ----------------------------------------------------------------------------

# Enable Prometheus metrics export (true/false)
ENABLE_PROMETHEUS_METRICS=true

# Prometheus metrics port
PROMETHEUS_PORT=9090

# Enable email alerts (true/false)
ENABLE_EMAIL_ALERTS=false

# Email configuration (if alerts are enabled)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your_email@gmail.com
SMTP_PASSWORD=your_password
ALERT_EMAIL_FROM=airflow@breweries.com
ALERT_EMAIL_TO=admin@breweries.com

# ----------------------------------------------------------------------------
# Execution Configuration
# ----------------------------------------------------------------------------

# Maximum number of active DAG runs
MAX_ACTIVE_RUNS=1

# DAG schedule interval (cron format)
# Default: Daily at 2 AM
DAG_SCHEDULE_INTERVAL=0 2 * * *

# Task execution timeout in seconds
TASK_EXECUTION_TIMEOUT=3600

# Number of task retries
TASK_RETRIES=3

# Delay between task retries in seconds
TASK_RETRY_DELAY=300
