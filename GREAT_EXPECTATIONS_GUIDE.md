# Great Expectations Integration - Data Quality Validation

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa **Great Expectations** para validaÃ§Ã£o automatizada de qualidade de dados em todas as camadas da arquitetura Medallion (Bronze, Silver e Gold).

Great Expectations Ã© um framework Python que permite:
- âœ… Definir "expectations" (expectativas) sobre seus dados
- ğŸ“Š Validar dados automaticamente em cada execuÃ§Ã£o do pipeline
- ğŸ“„ Gerar documentaÃ§Ã£o HTML interativa (Data Docs)
- ğŸš¨ Detectar anomalias e problemas de qualidade
- ğŸ“ˆ Rastrear qualidade ao longo do tempo

---

## ğŸ—ï¸ Arquitetura

```
Pipeline Airflow
â”‚
â”œâ”€ Bronze Ingestion
â”‚  â”œâ”€ Ingerir dados da API
â”‚  â””â”€ âœ“ Validate Bronze Quality (Great Expectations)
â”‚     â”œâ”€ Schema validation
â”‚     â”œâ”€ Uniqueness checks
â”‚     â”œâ”€ Volume anomaly detection
â”‚     â””â”€ Domain validation
â”‚
â”œâ”€ Silver Transformation
â”‚  â”œâ”€ Transformar e enrichar dados
â”‚  â””â”€ âœ“ Validate Silver Quality (Great Expectations)
â”‚     â”œâ”€ Data loss check
â”‚     â”œâ”€ Enrichment validation
â”‚     â”œâ”€ Geographic consistency
â”‚     â””â”€ Null Island detection
â”‚
â””â”€ Gold Aggregation
   â”œâ”€ Criar agregaÃ§Ãµes
   â””â”€ âœ“ Validate Gold Quality (Great Expectations)
      â”œâ”€ Aggregation consistency
      â”œâ”€ Top entities validation
      â””â”€ Mathematical integrity
```

---

## ğŸ“Š Expectations Implementadas por Camada

### **Bronze Layer** (Dados Brutos da API)

#### 1. **Schema Validation**
```python
expect_table_columns_to_match_ordered_list()
```
- **O que valida:** Verifica se todas as colunas esperadas da API existem
- **Por que Ã© importante:** Detecta mudanÃ§as no schema da API
- **EstatÃ­stica:** Lista de colunas presentes vs esperadas

#### 2. **Uniqueness - IDs Ãšnicos**
```python
expect_column_values_to_be_unique(column="id")
```
- **O que valida:** 100% dos IDs devem ser Ãºnicos (sem duplicatas)
- **Por que Ã© importante:** Evita processamento duplicado
- **EstatÃ­stica:** `unique_count / total_count` 
- **Exemplo:** 9,000 Ãºnicos de 9,000 total = âœ…

#### 3. **Completeness - Campos ObrigatÃ³rios**
```python
expect_column_values_to_not_be_null(column="id", mostly=1.0)
expect_column_values_to_not_be_null(column="name", mostly=0.99)
expect_column_values_to_not_be_null(column="brewery_type", mostly=0.95)
```
- **O que valida:** Campos crÃ­ticos nÃ£o podem ser nulos
- **Por que Ã© importante:** Garante dados mÃ­nimos para anÃ¡lise
- **EstatÃ­stica:** Taxa de completude por campo
- **TolerÃ¢ncia:** 
  - `id`: 100% (zero tolerÃ¢ncia)
  - `name`: 99% (1% pode falhar)
  - `brewery_type`: 95% (5% pode falhar)

#### 4. **Volume Check - DetecÃ§Ã£o de Anomalias**
```python
expect_table_row_count_to_be_between(min=5000, max=50000)
```
- **O que valida:** Volume de registros dentro do esperado
- **Por que Ã© importante:** Detecta problemas na API (downtime, rate limiting)
- **EstatÃ­stica:** Contagem total de registros
- **Alerta:** Se < 5k ou > 50k registros
- **Exemplo:** 8,500 registros = âœ… | 3,200 registros = âŒ (API com problema)

#### 5. **Domain Validation - Valores Conhecidos**
```python
expect_column_values_to_be_in_set(
    column="brewery_type",
    value_set=["micro", "nano", "regional", "brewpub", ...]
)
```
- **O que valida:** brewery_type sÃ³ pode ter valores catalogados
- **Por que Ã© importante:** Identifica novos tipos nÃ£o mapeados
- **EstatÃ­stica:** DistribuiÃ§Ã£o por tipo + tipos desconhecidos
- **Valores aceitos:** micro, nano, regional, brewpub, large, planning, bar, contract, proprietor, closed

#### 6. **Coordinate Ranges - ValidaÃ§Ã£o GeogrÃ¡fica**
```python
expect_column_values_to_be_between(
    column="latitude", 
    min_value=-90, 
    max_value=90,
    mostly=0.5
)
```
- **O que valida:** Coordenadas em range geogrÃ¡fico vÃ¡lido
- **Por que Ã© importante:** Detecta coordenadas invÃ¡lidas da API
- **EstatÃ­stica:** % de coordenadas vÃ¡lidas
- **TolerÃ¢ncia:** `mostly=0.5` = aceita 50% sem coordenadas (conhecido: ~26% da API nÃ£o tem coords)
- **Exemplo:** 74% com coords vÃ¡lidas = âœ…

#### 7. **Anomaly Detection - ComparaÃ§Ã£o HistÃ³rica**
```python
# Compara volume atual vs execuÃ§Ã£o anterior
variance = abs(current_count - previous_count) / previous_count
if variance > 0.20:  # VariaÃ§Ã£o > 20%
    logger.warning("ANOMALY DETECTED")
```
- **O que valida:** Volume nÃ£o varia >20% entre execuÃ§Ãµes
- **Por que Ã© importante:** Detecta mudanÃ§as bruscas suspeitas
- **EstatÃ­stica:** % de variaÃ§Ã£o vs Ãºltima execuÃ§Ã£o
- **Exemplo:** 
  - Ontem: 9,000 registros
  - Hoje: 9,500 registros
  - VariaÃ§Ã£o: 5.5% = âœ…
  - Hoje: 7,000 registros
  - VariaÃ§Ã£o: 22% = âš ï¸ ANOMALIA

---

### **Silver Layer** (Dados Transformados e Enriched)

#### 1. **Data Loss Check**
```python
expect_table_row_count_to_be_between(
    min_value=int(bronze_count * 0.95),
    max_value=bronze_count
)
```
- **O que valida:** MÃ¡ximo 5% de perda de dados Bronze â†’ Silver
- **Por que Ã© importante:** Evita perda silenciosa de dados
- **EstatÃ­stica:** Taxa de retenÃ§Ã£o = `silver_count / bronze_count`
- **Exemplo:**
  - Bronze: 9,000 registros
  - Silver: 8,900 registros
  - RetenÃ§Ã£o: 98.9% = âœ…
  - Silver: 8,400 registros
  - RetenÃ§Ã£o: 93.3% = âŒ (>5% de perda)

#### 2. **Country Normalization**
```python
expect_column_values_to_not_be_null(
    column="country_normalized",
    mostly=1.0
)
```
- **O que valida:** 100% dos registros tÃªm paÃ­s normalizado
- **Por que Ã© importante:** Essencial para particionamento e anÃ¡lises
- **EstatÃ­stica:** Taxa de normalizaÃ§Ã£o
- **Exemplo:** 9,000/9,000 com paÃ­s = âœ…

#### 3. **Coordinate Enrichment**
```python
expect_column_pair_values_to_be_in_set(
    column_A="latitude",
    column_B="longitude",
    mostly=0.85
)
```
- **O que valida:** 85%+ devem ter coordenadas (com geocoding)
- **Por que Ã© importante:** Valida sucesso do geocoding
- **EstatÃ­stica:** Cobertura de coordenadas
- **ComparaÃ§Ã£o:**
  - Bronze: 74% com coords (API)
  - Silver: 85%+ com coords (API + geocoding) = âœ…

#### 4. **Coordinate Validation**
```python
expect_column_values_to_be_in_set(
    column="coordinates_valid",
    value_set=[True],
    mostly=0.85
)
```
- **O que valida:** 85%+ coords geograficamente vÃ¡lidas
- **Por que Ã© importante:** Garante qualidade das coords enriched
- **EstatÃ­stica:** % de coordenadas que passam validaÃ§Ã£o geogrÃ¡fica
- **ValidaÃ§Ãµes incluÃ­das:**
  - Range check (lat: -90 a 90, lng: -180 a 180)
  - NÃ£o Ã© Null Island (0, 0)
  - Coords batem com paÃ­s (bounding box check)

#### 5. **Null Island Detection**
```python
expect_compound_columns_to_be_unique(
    column_list=["latitude", "longitude"]
)
```
- **O que valida:** Detecta coordenadas (0, 0) - "Null Island"
- **Por que Ã© importante:** Erro comum de geocoding
- **EstatÃ­stica:** Contagem de Null Island
- **Exemplo:** 0 registros em (0,0) = âœ…

#### 6. **Schema Enrichment**
```python
expect_table_column_count_to_be_between(
    min_value=20,
    max_value=30
)
```
- **O que valida:** Silver tem mais colunas que Bronze
- **Por que Ã© importante:** Confirma que enrichment ocorreu
- **EstatÃ­stica:** Contagem de colunas
- **Exemplo:** Bronze: 18 cols, Silver: 25 cols = âœ…

---

### **Gold Layer** (AgregaÃ§Ãµes)

#### 1. **Aggregation Consistency**
```python
expect_table_row_count_to_be_between(min=1, max=10000)
expect_column_values_to_be_between(
    column="count",
    min_value=1,
    max_value=silver_count
)
```
- **O que valida:** 
  - AgregaÃ§Ãµes nÃ£o vazias
  - Counts positivos e <= total Silver
- **Por que Ã© importante:** Garante integridade matemÃ¡tica
- **EstatÃ­stica:** Range de valores de agregaÃ§Ãµes
- **Exemplo:**
  - breweries_by_country tem 45 paÃ­ses
  - Maior count: 6,500 (USA)
  - Soma de todos: 9,000 = Silver count âœ…

#### 2. **Top Entities Validation**
```python
expect_column_values_to_be_in_set(
    column="country_normalized",
    value_set=["United States"]
)
```
- **O que valida:** USA deve estar no resultado
- **Por que Ã© importante:** USA tem ~70% das breweries - se nÃ£o aparecer, hÃ¡ erro
- **EstatÃ­stica:** PresenÃ§a de top entidades conhecidas
- **Exemplo:** USA presente = âœ…, USA ausente = âŒ

```python
expect_column_values_to_be_in_set(
    column="brewery_type",
    value_set=["micro"]
)
```
- **O que valida:** "micro" deve estar presente (tipo mais comum)
- **Por que Ã© importante:** ValidaÃ§Ã£o de consistÃªncia
- **EstatÃ­stica:** Top tipos presentes

---

## ğŸ“ˆ EstatÃ­sticas Calculadas

### **Durante ValidaÃ§Ã£o Bronze:**
```python
{
    "row_count": 9000,
    "column_count": 18,
    "null_counts": {
        "latitude": 2340,  # 26% sem coordenadas
        "phone": 3600      # 40% sem telefone
    },
    "duplicate_count": 0,
    "success_rate": 100.0,
    "passed_expectations": 8,
    "failed_expectations": 0
}
```

### **Durante ValidaÃ§Ã£o Silver:**
```python
{
    "row_count": 8950,
    "column_count": 25,
    "enrichment_stats": {
        "coordinate_coverage": 0.86,      # 86% com coords
        "valid_coordinates_rate": 0.84,   # 84% vÃ¡lidas
        "geocoded_rate": 0.12,            # 12% geocodificadas
        "country_normalized_rate": 1.0    # 100% com paÃ­s
    },
    "data_retention_rate": 0.994,         # 99.4% Bronzeâ†’Silver
    "success_rate": 95.5
}
```

### **Durante ValidaÃ§Ã£o Gold:**
```python
{
    "total_aggregations": 4,
    "passed_aggregations": 4,
    "failed_aggregations": 0,
    "aggregation_details": {
        "breweries_by_country": {
            "rows": 45,
            "top_country": "United States",
            "top_count": 6300
        },
        "breweries_by_type": {
            "rows": 10,
            "top_type": "micro",
            "top_count": 5400
        }
    }
}
```

---

## ğŸš€ Como Usar

### **1. ExecuÃ§Ã£o AutomÃ¡tica (via Airflow)**
As validaÃ§Ãµes sÃ£o executadas automaticamente em cada run do pipeline:

```
Bronze Ingestion â†’ Validate Bronze Quality â†’ Silver Transform â†’ ...
```

### **2. ExecuÃ§Ã£o Manual**
```python
from pyspark.sql import SparkSession
from src.validation import BreweriesDataValidator

# Inicializar Spark
spark = SparkSession.builder.getOrCreate()

# Ler dados
bronze_df = spark.read.format("delta").load("/opt/airflow/lakehouse/bronze/breweries")

# Criar validator
validator = BreweriesDataValidator(spark=spark)

# Validar
result = validator.validate_bronze_layer(
    df=bronze_df,
    execution_date="2026-01-24"
)

# Verificar resultado
if result['success']:
    print(f"âœ… Validation passed! ({result['success_rate']:.1f}%)")
else:
    print(f"âŒ {result['failed_expectations_count']} expectations failed")
    for failure in result['failed_details']:
        print(f"   - {failure['expectation']}: {failure['description']}")
```

### **3. Visualizar Data Docs (RelatÃ³rios HTML)**
ApÃ³s execuÃ§Ã£o, Great Expectations gera documentaÃ§Ã£o HTML interativa:

```bash
# LocalizaÃ§Ã£o dos Data Docs
cd /opt/airflow/great_expectations/uncommitted/data_docs/local_site

# Abrir no navegador
# index.html
```

**O que vocÃª verÃ¡:**
- ğŸ“Š Dashboard de qualidade
- ğŸ“ˆ GrÃ¡ficos de tendÃªncia
- ğŸ¯ % de sucesso por expectation
- ğŸ“‹ Profiling estatÃ­stico automÃ¡tico
- ğŸ” Drill-down em falhas

---

## ğŸ¯ BenefÃ­cios para o Case de Entrevista

### **1. Demonstra Maturidade TÃ©cnica**
- Data quality Ã© crÃ­tico em produÃ§Ã£o
- Mostra preocupaÃ§Ã£o com governanÃ§a

### **2. Proativo vs Reativo**
- Detecta problemas antes de impactar anÃ¡lises
- NÃ£o espera usuÃ¡rios reportarem bugs

### **3. DocumentaÃ§Ã£o AutomÃ¡tica**
- Data Docs impressionam visualmente
- CatÃ¡logo de dados self-service

### **4. PadrÃ£o da IndÃºstria**
- Usado por Netflix, Uber, Airbnb
- Framework amplamente adotado

### **5. FÃ¡cil de Mostrar**
- RelatÃ³rio HTML bonito
- MÃ©tricas claras e visuais

---

## ğŸ“Š Exemplos de Output

### **Console Output (Airflow Logs):**
```
================================================================================
ğŸ” VALIDATING BRONZE LAYER WITH GREAT EXPECTATIONS
================================================================================
ğŸ“Š DataFrame Stats: 9,000 rows, 18 columns
ğŸ“Š Validation Results:
   Total Expectations: 8
   âœ… Passed: 8
   âŒ Failed: 0
   Success Rate: 100.0%
ğŸ“„ Data Docs generated at: /opt/airflow/great_expectations/uncommitted/data_docs/local_site/index.html
```

### **XCom Output (para debugging):**
```json
{
  "success": true,
  "suite_name": "bronze_quality_suite",
  "total_expectations": 8,
  "passed_expectations": 8,
  "failed_expectations_count": 0,
  "success_rate": 100.0,
  "statistics": {
    "row_count": 9000,
    "column_count": 18,
    "null_counts": {...}
  }
}
```

---

## ğŸ”§ ConfiguraÃ§Ã£o

Great Expectations Ã© configurado automaticamente na primeira execuÃ§Ã£o:

```
great_expectations/
â”œâ”€â”€ great_expectations.yml         # ConfiguraÃ§Ã£o principal
â”œâ”€â”€ checkpoints/                   # Checkpoints por layer
â”‚   â”œâ”€â”€ bronze_checkpoint.yml
â”‚   â”œâ”€â”€ silver_checkpoint.yml
â”‚   â””â”€â”€ gold_checkpoint.yml
â”œâ”€â”€ expectations/                  # Expectation suites
â”‚   â”œâ”€â”€ bronze_quality_suite.json
â”‚   â”œâ”€â”€ silver_quality_suite.json
â”‚   â””â”€â”€ gold_quality_suite.json
â””â”€â”€ uncommitted/
    â””â”€â”€ data_docs/
        â””â”€â”€ local_site/            # DocumentaÃ§Ã£o HTML
            â””â”€â”€ index.html         # ğŸ“„ Abrir no navegador!
```

---

## ğŸ’¡ Dicas para ApresentaÃ§Ã£o

### **Durante a Entrevista:**

1. **Abra os Data Docs HTML** - Impacto visual forte
2. **Mostre as estatÃ­sticas** - NÃºmeros concretos impressionam
3. **Explique a lÃ³gica** - Por que cada expectation Ã© importante
4. **Conecte com produÃ§Ã£o** - "Em prod, isso alertaria via Slack"
5. **Fale de trade-offs** - "mostly=0.85 porque sabemos que 15% nÃ£o terÃ£o coords"

### **Perguntas que vocÃª pode responder:**

**Q: "Como vocÃª garante qualidade dos dados?"**
âœ… "Implementei Great Expectations com X expectations validando schema, volume, domÃ­nio e consistÃªncia. Cada execuÃ§Ã£o gera relatÃ³rio de qualidade."

**Q: "E se os dados mudarem?"**
âœ… "Tenho anomaly detection comparando volume entre execuÃ§Ãµes. Se variar >20%, alerta automÃ¡tico."

**Q: "Como vocÃª documenta os dados?"**
âœ… "Great Expectations gera Data Docs automaticamente com profiling estatÃ­stico e catÃ¡logo de expectations."

---

## ğŸ“š ReferÃªncias

- [Great Expectations Docs](https://docs.greatexpectations.io/)
- [Expectation Gallery](https://greatexpectations.io/expectations/)
- [Best Practices](https://docs.greatexpectations.io/docs/guides/miscellaneous/best_practices/)

---

## ğŸ¯ Next Steps (Futuro)

Para expandir ainda mais:

1. **Alerting:** Integrar com Slack/Discord para notificaÃ§Ãµes de falha
2. **Data Contracts:** Formalizar contratos de dados entre camadas
3. **Custom Expectations:** Criar expectations especÃ­ficas do domÃ­nio
4. **Performance:** Adicionar expectations de tempo de execuÃ§Ã£o (SLA)
5. **Comparisons:** Comparar distribuiÃ§Ãµes dia a dia (data drift)

---

## âœ… Checklist de ValidaÃ§Ã£o

- [x] Bronze: Schema completo e IDs Ãºnicos
- [x] Bronze: Volume dentro do esperado (5k-50k)
- [x] Bronze: Tipos de brewery conhecidos
- [x] Bronze: Coordenadas em ranges vÃ¡lidos
- [x] Silver: Data loss < 5%
- [x] Silver: PaÃ­s normalizado para 100%
- [x] Silver: 85%+ com coordenadas vÃ¡lidas
- [x] Silver: Sem Null Island (0,0)
- [x] Gold: AgregaÃ§Ãµes nÃ£o vazias
- [x] Gold: USA no top paÃ­ses
- [x] Gold: Counts positivos e consistentes

**Status Geral: âœ… IMPLEMENTADO**
