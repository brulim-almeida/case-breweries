# Case Breweries Data Lake

O desafio deste case foi desenvolver um pipeline de dados robusto para extrair, processar e armazenar informaÃ§Ãµes de cervejarias a partir da API Open Brewery DB. O pipeline segue a arquitetura Medallion (Bronze, Silver e Gold) implementada com Apache Airflow, PySpark e Delta Lake.

<img width="935" height="418" alt="image" src="https://github.com/user-attachments/assets/e75faccd-fc85-47a8-84f8-f6b73fb8ccbb" />


> ğŸ’¾ Arquitetura da Pipeline de Dados

## Resumo dos Principais Conceitos e Tecnologias Utilizadas

* **Pipeline orquestrado no Apache Airflow** com TaskFlow API
* **Airflow rodando em containers Docker** com CeleryExecutor para processamento distribuÃ­do
* **Processamento via PySpark 3.5.0** com suporte a Delta Lake 3.1.0
* **Arquitetura Medallion** (Bronze â†’ Silver â†’ Gold) para organizaÃ§Ã£o e qualidade dos dados
* **Processamento incremental** na Silver layer para evitar reprocessamento de dados histÃ³ricos
* **Delta Lake** para ACID transactions e versionamento de dados
* **Boas prÃ¡ticas de engenharia**: cÃ³digo modular, documentado e testÃ¡vel
* **Data Quality** integrado com validaÃ§Ãµes e mÃ©tricas de qualidade em cada camada
* **XCom** para comunicaÃ§Ã£o entre tasks e rastreamento de metadados
* **Dashboard Streamlit** ğŸ¨ para visualizaÃ§Ã£o interativa dos dados Gold (Ponto Extra)

## Estrutura de DiretÃ³rios e Arquivos

```
case-breweries/
â”œâ”€â”€ .env                          # VariÃ¡veis de ambiente
â”œâ”€â”€ .env.example                  # Template de configuraÃ§Ã£o
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ Dockerfile                    # Imagem customizada Airflow + PySpark
â”œâ”€â”€ docker-compose.yaml           # OrquestraÃ§Ã£o completa (8 serviÃ§os)
â”œâ”€â”€ pytest.ini                    # ConfiguraÃ§Ã£o de testes
â”œâ”€â”€ requirements.txt              # DependÃªncias Python
â”‚
â”œâ”€â”€ airflow/                      # ConfiguraÃ§Ãµes Airflow
â”‚   â””â”€â”€ README.md                 # DocumentaÃ§Ã£o de setup
â”‚
â”œâ”€â”€ dags/                         # DAGs do Airflow
â”‚   â””â”€â”€ breweries_pipeline_dag.py # Pipeline principal
â”‚
â”œâ”€â”€ dashboards/                   # ğŸ¨ Dashboard Streamlit (Ponto Extra)
â”‚   â””â”€â”€ streamlit_app.py          # App interativo com visualizaÃ§Ãµes
â”‚
â”œâ”€â”€ src/                          # CÃ³digo-fonte principal
â”‚   â”œâ”€â”€ api/                      # Cliente API
â”‚   â”‚   â””â”€â”€ brewery_client.py    # IntegraÃ§Ã£o com Open Brewery DB
â”‚   â”œâ”€â”€ config/                   # ConfiguraÃ§Ãµes
â”‚   â”‚   â””â”€â”€ settings.py           # Settings centralizados
â”‚   â””â”€â”€ layers/                   # Camadas Medallion
â”‚       â”œâ”€â”€ bronze_layer.py       # IngestÃ£o de dados brutos
â”‚       â”œâ”€â”€ silver_layer.py       # TransformaÃ§Ã£o e curadoria
â”‚       â””â”€â”€ gold_layer.py         # AgregaÃ§Ãµes de negÃ³cio
â”‚
â”œâ”€â”€ tests/                        # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ test_bronze_layer.py
â”‚   â”œâ”€â”€ test_silver_layer.py
â”‚   â””â”€â”€ test_gold_layer.py
â”‚
â”œâ”€â”€ utils/                        # UtilitÃ¡rios
â”‚   â””â”€â”€ delta_spark.py            # Helper para Delta Lake
â”‚
â”œâ”€â”€ lakehouse/                    # Data Lake
â”‚   â”œâ”€â”€ bronze/                   # Dados brutos (JSON particionado)
â”‚   â”œâ”€â”€ silver/                   # Dados curados (Delta Lake)
â”‚   â””â”€â”€ gold/                     # AgregaÃ§Ãµes (Delta Lake)
â”‚
â””â”€â”€ logs/                         # Logs do Airflow
```

## DescriÃ§Ã£o da DAG [breweries_pipeline_dag.py]

<img width="297" height="313" alt="image" src="https://github.com/user-attachments/assets/0d298aac-51a8-4554-b186-54f322c1f7c0" />

<img width="1151" height="302" alt="image" src="https://github.com/user-attachments/assets/d4eeab73-0879-4a18-bd7c-58cdcd223fa7" />

O pipeline Ã© composto por 4 tasks principais encadeadas:

### 1ï¸âƒ£ Bronze Ingestion (`bronze_ingestion`)
**ResponsÃ¡vel por:**
- Extrair dados da API Open Brewery DB com paginaÃ§Ã£o automÃ¡tica (~9,000 cervejarias)
- Persistir dados brutos em formato JSON no lakehouse/bronze
- Particionamento temporal: `year=YYYY/month=MM/day=DD/breweries_TIMESTAMP.json`
- Retornar metadados via XCom: `total_records`, `pages_processed`, `ingestion_path`, `status`

**Tratamento de erros:** Retry atÃ© 3x com backoff exponencial (5min â†’ 10min â†’ 20min)

### 2ï¸âƒ£ Silver Transformation (`silver_transformation`)
**ResponsÃ¡vel por:**
- **Processamento incremental**: consome APENAS o arquivo da ingestÃ£o atual (via `ingestion_path`)
- Limpeza e normalizaÃ§Ã£o de dados (trim, null handling, padronizaÃ§Ã£o)
- Enriquecimento: `full_address`, flags `has_coordinates`, `has_contact`, timestamp `processed_at`
- Escrita em Delta Lake com particionamento: `country_normalized`, `state`
- CÃ¡lculo de mÃ©tricas de qualidade: completeness rate, coordinate coverage, contact coverage
- Retornar metadados: `output_records`, `distinct_countries`, `distinct_types`, `quality_metrics`

**InovaÃ§Ã£o:** Evita reprocessamento de histÃ³rico completo (soluÃ§Ã£o incremental)

### 3ï¸âƒ£ Gold Aggregation (`gold_aggregation`)
**ResponsÃ¡vel por:**
- Consumir dados curados da Silver layer
- Criar 6 agregaÃ§Ãµes estratÃ©gicas de negÃ³cio:
  - `by_country`: Total de cervejarias por paÃ­s
  - `by_type`: DistribuiÃ§Ã£o por tipo de cervejaria
  - `by_state`: DistribuiÃ§Ã£o por estado (top 20)
  - `top_cities`: Top 10 cidades com mais cervejarias
  - `coordinate_coverage`: MÃ©tricas de cobertura geogrÃ¡fica
  - `contact_summary`: MÃ©tricas de informaÃ§Ãµes de contato
- Persistir cada agregaÃ§Ã£o como dataset Delta Lake separado
- OtimizaÃ§Ã£o para consumo analÃ­tico (baixa latÃªncia)

### 4ï¸âƒ£ Validate Pipeline (`validate_pipeline`)
**ResponsÃ¡vel por:**
- Validar integridade dos metadados de todas as camadas
- Verificar status de execuÃ§Ã£o (SUCCESS vs FAILURE)
- Calcular `data_loss_rate` comparando registros Bronze vs Silver
- Gerar relatÃ³rio consolidado com:
  - Status final: SUCCESS/FAILURE
  - MÃ©tricas de cada camada
  - Indicadores de qualidade (paÃ­ses, tipos, cobertura)
  - Taxa de perda de dados (esperado: 0%)

**Callback:** Em caso de falha, aciona `on_failure_callback` para notificaÃ§Ã£o

## Mais Detalhes sobre a DAG

### Data Quality
A validaÃ§Ã£o de qualidade foi implementada em mÃºltiplas camadas:
- **Bronze**: ValidaÃ§Ã£o de schema JSON e total de registros
- **Silver**: MÃ©tricas de completeness, coordinate coverage, contact coverage, contagem de valores Ãºnicos
- **Gold**: ValidaÃ§Ã£o de agregaÃ§Ãµes e consistÃªncia de totais
- **Pipeline**: ValidaÃ§Ã£o end-to-end com cÃ¡lculo de data loss rate

PossÃ­veis evoluÃ§Ãµes: Great Expectations, Soda Core, alertas via Slack/email

### Monitoramento
ImplementaÃ§Ã£o atual:
- **XCom**: Rastreamento de metadados entre tasks
- **Airflow Logs**: Logs estruturados com timestamps e contexto
- **MÃ©tricas de execuÃ§Ã£o**: Duration, records processed, quality metrics

EvoluÃ§Ãµes possÃ­veis:
- IntegraÃ§Ã£o com **Prometheus + Grafana** para dashboards em tempo real
- Alertas proativos via **PagerDuty** ou **Opsgenie**
- Observabilidade com **OpenTelemetry**

### Processamento Incremental
**Problema resolvido:** Silver layer inicialmente processava TODO o histÃ³rico Bronze a cada execuÃ§Ã£o (multiplicaÃ§Ã£o de dados).

**SoluÃ§Ã£o implementada:**
```python
# DAG passa o caminho especÃ­fico da ingestÃ£o
silver.transform_breweries(ingestion_path=bronze_metadata['ingestion_path'])

# Silver layer processa apenas o arquivo especÃ­fico
if ingestion_path:
    df = spark.read.json(ingestion_path)  # âœ… Incremental
else:
    df = spark.read.json(f"{bronze_path}/year=*/month=*/day=*/*.json")  # Full load
```

**Resultado:** 0% data loss, processamento eficiente, sem duplicaÃ§Ã£o

## Arquitetura de Deployment

### Docker Compose (7 serviÃ§os)
- **postgres**: Metadata database (Airflow backend)
- **redis**: Message broker (Celery)
- **scheduler**: Agendador de DAGs
- **worker**: Executor de tasks (CeleryExecutor)
- **webserver**: Interface web (porta 8080)
- **triggerer**: Deferrable operators
- **flower**: Monitoramento Celery (porta 5555)

### Volumes Persistentes
- `./dags` â†’ `/opt/airflow/dags`
- `./logs` â†’ `/opt/airflow/logs`
- `./lakehouse` â†’ `/opt/airflow/lakehouse`
- `./src` â†’ `/opt/airflow/src`
- `./utils` â†’ `/opt/airflow/utils`

## Pontos de Melhoria e PrÃ³ximos Passos

### 1. Escalabilidade e Cloud-Native
**Desafio atual:** Spark rodando em Ãºnico worker do Airflow (limitaÃ§Ã£o de recursos)

**SoluÃ§Ã£o proposta:**
- Migrar para **Kubernetes** (EKS, GKE ou AKS)
- Implementar **Spark Operator** para auto-scaling de Spark executors
- Utilizar **Airflow on K8s** com KubernetesExecutor

**BenefÃ­cios:** Alta disponibilidade, elasticidade, melhor utilizaÃ§Ã£o de recursos

### 2. CI/CD e Infraestrutura como CÃ³digo
**ImplementaÃ§Ãµes sugeridas:**
- **Terraform** para provisionamento de infra (AWS/GCP/Azure)
- **GitHub Actions** ou **GitLab CI** para pipelines CI/CD
- **ArgoCD** para GitOps e deployment automatizado
- **Testes automatizados** em mÃºltiplos ambientes (dev, staging, prod)

**BenefÃ­cios:** FinOps, reprodutibilidade, rollback rÃ¡pido, segregaÃ§Ã£o de ambientes

### 3. SeguranÃ§a e GovernanÃ§a
- **Secrets Management**: Migrar para AWS Secrets Manager ou HashiCorp Vault
- **IAM Roles**: Implementar least privilege access

### 4. OtimizaÃ§Ãµes de Performance
- **Z-Ordering** no Delta Lake para queries otimizadas
- **Data Skipping** com estatÃ­sticas de partiÃ§Ãµes
- **Compaction** automÃ¡tico de small files
- **Caching** de datasets frequentes

### 5. Advanced Analytics
- **Streaming**: Implementar ingestÃ£o em tempo real com Kafka + Spark Streaming
- **Data Quality**: Integrar Great Expectations com alertas automÃ¡ticos

## ğŸ¨ Dashboard Interativo com Streamlit (Ponto Extra)

Como demonstraÃ§Ã£o adicional das capacidades do pipeline, foi implementado um **dashboard interativo com Streamlit** para visualizaÃ§Ã£o dos dados agregados na camada Gold.

### CaracterÃ­sticas do Dashboard

**ğŸ“Š 4 Abas de AnÃ¡lise:**
1. **ğŸŒ Geographic**: DistribuiÃ§Ã£o global de cervejarias com visualizaÃ§Ã£o comparativa (incluindo/excluindo EUA)
2. **ğŸ·ï¸ Types**: AnÃ¡lise por tipo de cervejaria com grÃ¡ficos de pizza e barras
3. **ğŸ“ˆ Quality**: MÃ©tricas de qualidade dos dados com gauges interativos (cobertura de coordenadas, informaÃ§Ãµes de contato)
4. **ğŸ™ï¸ Cities**: AnÃ¡lise por estados com treemap hierÃ¡rquico e top 20 rankings

**ğŸ”§ Stack TÃ©cnico:**
- **Streamlit 1.31.0**: Framework web interativo
- **Plotly 5.18.0**: VisualizaÃ§Ãµes interativas e responsivas
- **deltalake 0.15.0**: Leitura nativa de Delta Lake sem overhead Java/Spark

**ğŸ¯ DecisÃµes Arquiteturais:**
- UtilizaÃ§Ã£o da biblioteca `deltalake` Python para leitura direta dos arquivos Delta, evitando a complexidade de inicializar Spark/JVM no container do Streamlit
- Dashboard consome diretamente as tabelas Gold agregadas pelo pipeline Airflow
- Deploy como serviÃ§o adicional no Docker Compose com profile dedicado

### Como Executar o Dashboard

```bash
# Iniciar todos os serviÃ§os incluindo Streamlit
docker compose --profile streamlit up -d

# Acessar o dashboard
# URL: http://localhost:8501
```

O dashboard se conecta automaticamente aos dados da camada Gold e oferece:
- âœ… VisualizaÃ§Ãµes interativas com zoom, pan e export de imagens
- âœ… Filtros e drill-down para anÃ¡lise detalhada
- âœ… MÃ©tricas de qualidade em tempo real
- âœ… Insights automÃ¡ticos sobre distribuiÃ§Ã£o e cobertura de dados

**ğŸ’¡ BenefÃ­cios:**
- DemonstraÃ§Ã£o visual do valor agregado pelo pipeline
- Interface amigÃ¡vel para stakeholders nÃ£o-tÃ©cnicos
- ValidaÃ§Ã£o imediata da qualidade das agregaÃ§Ãµes Gold
- Base para desenvolvimento de analytics avanÃ§ados

### Parar o Dashboard

```bash
# Parar apenas o Streamlit
docker compose stop streamlit

# Parar todos os serviÃ§os
docker compose --profile streamlit down
```

## Passos para Executar o Projeto

> [!NOTE]
> Projeto desenvolvido e testado em ambiente Linux (Ubuntu/Debian)

### Requisitos
- Docker 20.10+
- Docker Compose 2.0+
- 8GB RAM mÃ­nimo
- 20GB espaÃ§o em disco

### 1. Clonar o RepositÃ³rio
```bash
git clone https://github.com/brulim-almeida/case-breweries.git
cd case-breweries
```

### 2. Configurar VariÃ¡veis de Ambiente
```bash
cp .env.example .env
# Editar .env se necessÃ¡rio (configuraÃ§Ãµes padrÃ£o jÃ¡ funcionam)
```

### 3. Ajustar PermissÃµes (Linux)
```bash
sudo chmod -R 777 ./logs ./lakehouse
```

### 4. Build da Imagem Docker
```bash
docker build -t airflow-breweries:latest .
```

> [!TIP]
> A imagem jÃ¡ inclui OpenJDK 17, PySpark 3.5.0 e Delta Lake 3.1.0

### 5. Iniciar os ServiÃ§os
```bash
docker compose up -d
```

Aguarde ~2 minutos para inicializaÃ§Ã£o completa. Verifique status:
```bash
docker compose ps
```

### 6. Acessar o Airflow Webserver
```
URL: http://localhost:8080
Login: airflow
Senha: airflow
```

### 7. Executar a DAG
1. Na interface web, vÃ¡ em **DAGs**
2. Localize `breweries_pipeline_dag`
3. Ative a DAG (toggle on)
4. Clique em **Trigger DAG** (botÃ£o â–¶ï¸)

### 8. Monitorar ExecuÃ§Ã£o
- **Graph View**: Visualizar dependÃªncias entre tasks
- **Grid View**: HistÃ³rico de execuÃ§Ãµes
- **Logs**: Logs detalhados de cada task
- **Flower**: http://localhost:5555 (monitoramento Celery)

### 9. Validar Resultados
```bash
# Verificar dados Bronze
ls -lh lakehouse/bronze/breweries/year=*/month=*/day=*/

# Verificar dados Silver (Delta Lake)
ls -lh lakehouse/silver/breweries/_delta_log/

# Verificar agregaÃ§Ãµes Gold
ls -lh lakehouse/gold/breweries/
```

### 10. Parar os ServiÃ§os
```bash
docker compose down  # Para os serviÃ§os
docker compose down -v  # Para e remove volumes (reset completo)
```

## Estrutura de Dados

### Bronze Layer
```json
{
  "id": "5128df48-79fc-4f0f-8b52-d06be54d0cec",
  "name": "Foo Bar Brewery",
  "brewery_type": "micro",
  "address_1": "1234 Main St",
  "city": "San Francisco",
  "state": "California",
  "postal_code": "94102",
  "country": "United States",
  "longitude": "-122.419906",
  "latitude": "37.7749",
  "phone": "4155551234",
  "website_url": "http://foobarbrewery.com"
}
```

### Silver Layer (Delta Lake)
Adiciona campos enriquecidos:
- `full_address`: String concatenada completa
- `has_coordinates`: Boolean (latitude e longitude preenchidas)
- `has_contact`: Boolean (phone ou website preenchido)
- `processed_at`: Timestamp de processamento
- `country_normalized`: PaÃ­s normalizado
- `brewery_type_normalized`: Tipo normalizado

### Gold Layer Aggregations
- **by_country**: `country`, `total_breweries`
- **by_type**: `brewery_type`, `total_breweries`
- **by_state**: `country`, `state`, `total_breweries`
- **top_cities**: `city`, `state`, `country`, `total_breweries`
- **coordinate_coverage**: `total_breweries`, `with_coordinates`, `coverage_percentage`
- **contact_summary**: `total_breweries`, `with_phone`, `with_website`, `contact_coverage`

## Testes

Executar testes unitÃ¡rios:
```bash
# Dentro do container Airflow
docker compose exec airflow-webserver pytest tests/ -v

# Com coverage
docker compose exec airflow-webserver pytest tests/ --cov=src --cov-report=html
```

## Troubleshooting

### Erro: "No space left on device"
```bash
docker system prune -a --volumes
```

### Erro: "Port 8080 already in use"
Editar `docker-compose.yaml` e alterar porta do webserver

### DAG nÃ£o aparece na interface
```bash
# Verificar logs do scheduler
docker compose logs airflow-scheduler -f

# Validar sintaxe da DAG
docker compose exec airflow-webserver python /opt/airflow/dags/breweries_pipeline_dag.py
```

### Tasks falhando com erro de memÃ³ria
Aumentar recursos do Docker Desktop ou reduzir `spark.executor.memory` em `utils/delta_spark.py`

## ConclusÃ£o & Agradecimentos

Este projeto demonstra a implementaÃ§Ã£o completa de um Data Lake moderno utilizando as melhores prÃ¡ticas de engenharia de dados:
- âœ… Arquitetura Medallion para organizaÃ§Ã£o e qualidade
- âœ… Processamento incremental para eficiÃªncia
- âœ… OrquestraÃ§Ã£o robusta com Airflow
- âœ… ACID transactions com Delta Lake
- âœ… CÃ³digo modular, testÃ¡vel e documentado
- âœ… Deploy containerizado e reprodutÃ­vel

O case oferece uma base sÃ³lida para evoluÃ§Ãµes futuras em cloud, ML pipelines e analytics avanÃ§ado.

AgradeÃ§o pela oportunidade e estou disponÃ­vel para qualquer esclarecimento!

---

**Autor:** [Bruno Lima](https://www.linkedin.com/in/brulimalmeida/)  
**RepositÃ³rio:** [case-breweries](https://github.com/brulim-almeida/case-breweries)  
