# Case Breweries Data Lake

O desafio deste case foi desenvolver um pipeline de dados robusto para extrair, processar e armazenar informaÃ§Ãµes de cervejarias a partir da API Open Brewery DB. O pipeline segue a arquitetura Medallion (Bronze, Silver e Gold) implementada com Apache Airflow, PySpark e Delta Lake.

<img width="935" height="418" alt="image" src="https://github.com/user-attachments/assets/e75faccd-fc85-47a8-84f8-f6b73fb8ccbb" />


> ğŸ’¾ Arquitetura da Pipeline de Dados

## Resumo dos Principais Conceitos e Tecnologias Utilizadas

* **Pipeline orquestrado no Apache Airflow** com TaskFlow API
* **Airflow rodando em containers Docker** com CeleryExecutor para processamento distribuÃ­do
* **Processamento via PySpark 3.5.0** com suporte a Delta Lake 3.1.0
* **Arquitetura Medallion** (Bronze â†’ Silver â†’ Gold) para organizaÃ§Ã£o e qualidade dos dados
* **Processamento incremental** na Silver layer para evitar reprocessamento de dados histÃ³ricos
* **Delta Lake** para ACID transactions e versionamento de dados
* **Boas prÃ¡ticas de engenharia**: cÃ³digo modular, documentado e testÃ¡vel
* **Data Quality** integrado com validaÃ§Ãµes e mÃ©tricas de qualidade em cada camada
* **XCom** para comunicaÃ§Ã£o entre tasks e rastreamento de metadados

---

## ğŸ¯ Funcionalidades Extras Implementadas (AlÃ©m do Case Original)

Este projeto vai alÃ©m dos requisitos bÃ¡sicos do case, incluindo funcionalidades avanÃ§adas que agregam valor significativo ao pipeline:

### 1. ğŸ¨ Dashboard Interativo com Streamlit
**Por que foi adicionado:** Demonstrar o valor dos dados processados atravÃ©s de visualizaÃ§Ãµes interativas e acessÃ­veis para stakeholders nÃ£o-tÃ©cnicos.

**Funcionalidades:**
- 5 abas de anÃ¡lise (Maps, Geographic, Types, Quality, Cities)
- VisualizaÃ§Ãµes interativas com Plotly (mapas, treemaps, gauges)
- MÃ©tricas de qualidade em tempo real
- Filtros dinÃ¢micos por paÃ­s, tipo e regiÃ£o
- Leitura nativa de Delta Lake sem overhead Spark

### 2. ğŸŒ Geocoding AutomÃ¡tico para Coordenadas Faltantes
**Por que foi adicionado:** ~26% das cervejarias nÃ£o possuem coordenadas na API, limitando anÃ¡lises geogrÃ¡ficas. A soluÃ§Ã£o enriquece automaticamente esses dados.

**Funcionalidades:**
- IntegraÃ§Ã£o com API Nominatim (OpenStreetMap)
- Geocoding inteligente com estratÃ©gia de fallback
- Rate limiting respeitando limites da API (1 req/seg)
- MÃ©tricas detalhadas: taxa de sucesso, cobertura, performance
- Processamento batch configurÃ¡vel (100-1000 registros por execuÃ§Ã£o)

**Resultados esperados:**
- Melhoria de cobertura geogrÃ¡fica de ~74% para ~85%+
- ViabilizaÃ§Ã£o de anÃ¡lises espaciais completas
- Logs detalhados de sucesso/falha para auditoria

### 3. âœ… ValidaÃ§Ã£o GeogrÃ¡fica de Coordenadas
**Por que foi adicionado:** Algumas coordenadas da API (e do geocoding) sÃ£o incorretas, resultando em pontos no oceano ou paÃ­ses errados.

**ValidaÃ§Ãµes implementadas:**
- Range check: latitude (-90 a 90), longitude (-180 a 180)
- DetecÃ§Ã£o de "Null Island" (0,0) - erro comum de geocoding
- ConsistÃªncia geogrÃ¡fica: verifica se coordenadas batem com paÃ­s informado
- Bounding boxes para 13 paÃ­ses principais (USA, UK, Brasil, Alemanha, etc.)
- Coluna `coordinates_valid` para filtragem automÃ¡tica

**BenefÃ­cios:**
- Mapas limpos sem pontos suspeitos no oceano
- Maior confiabilidade em anÃ¡lises geogrÃ¡ficas
- IdentificaÃ§Ã£o de problemas de qualidade para correÃ§Ã£o

### 4. ğŸ“Š Tabela Completa de Breweries na Gold Layer
**Por que foi adicionado:** O dashboard precisa acessar dados individuais de cervejarias (nÃ£o apenas agregaÃ§Ãµes).

**ImplementaÃ§Ã£o:**
- Tabela `breweries` completa (nÃ£o particionada) na Gold layer
- Otimizada para consultas analÃ­ticas rÃ¡pidas
- Inclui todas as colunas enriched da Silver + validaÃ§Ãµes
- Base para anÃ¡lises exploratÃ³rias e drill-down

### 5. ğŸ“ˆ MÃ©tricas AvanÃ§adas de Data Quality
**AlÃ©m das mÃ©tricas bÃ¡sicas, foram implementadas:**
- Cobertura de coordenadas (antes/depois do geocoding)
- Taxa de melhoria de qualidade
- Breakdown de falhas de validaÃ§Ã£o
- Performance de geocoding (registros/segundo)
- Taxa de perda de dados entre camadas (data loss rate)

---

## Estrutura de DiretÃ³rios e Arquivos

```
case-breweries/
â”œâ”€â”€ .env                          # VariÃ¡veis de ambiente
â”œâ”€â”€ .env.example                  # Template de configuraÃ§Ã£o
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ Dockerfile                    # Imagem customizada Airflow + PySpark
â”œâ”€â”€ docker-compose.yaml           # OrquestraÃ§Ã£o completa (8 serviÃ§os)
â”œâ”€â”€ pytest.ini                    # ConfiguraÃ§Ã£o de testes
â”œâ”€â”€ requirements.txt              # DependÃªncias Python
â”‚
â”œâ”€â”€ airflow/                      # ConfiguraÃ§Ãµes Airflow
â”‚   â””â”€â”€ README.md                 # DocumentaÃ§Ã£o de setup
â”‚
â”œâ”€â”€ dags/                         # DAGs do Airflow
â”‚   â””â”€â”€ breweries_pipeline_dag.py # Pipeline principal
â”‚
â”œâ”€â”€ dashboards/                   # ğŸ¨ Dashboard Streamlit (EXTRA)
â”‚   â””â”€â”€ streamlit_app.py          # App interativo com visualizaÃ§Ãµes
â”‚
â”œâ”€â”€ src/                          # CÃ³digo-fonte principal
â”‚   â”œâ”€â”€ api/                      # Cliente API
â”‚   â”‚   â””â”€â”€ brewery_client.py    # IntegraÃ§Ã£o com Open Brewery DB
â”‚   â”œâ”€â”€ config/                   # ConfiguraÃ§Ãµes
â”‚   â”‚   â””â”€â”€ settings.py           # Settings centralizados
â”‚   â”œâ”€â”€ enrichment/               # Enriquecimento de dados (EXTRA)
â”‚   â”‚   â”œâ”€â”€ geocoding.py          # Geocoding com Nominatim API
â”‚   â”‚   â””â”€â”€ test_geocoding.py    # Testes de geocoding
â”‚   â””â”€â”€ layers/                   # Camadas Medallion
â”‚       â”œâ”€â”€ bronze_layer.py       # IngestÃ£o de dados brutos
â”‚       â”œâ”€â”€ silver_layer.py       # TransformaÃ§Ã£o + Geocoding + ValidaÃ§Ã£o
â”‚       â””â”€â”€ gold_layer.py         # AgregaÃ§Ãµes + Tabela completa
â”‚
â”œâ”€â”€ tests/                        # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ test_bronze_layer.py
â”‚   â”œâ”€â”€ test_silver_layer.py
â”‚   â””â”€â”€ test_gold_layer.py
â”‚
â”œâ”€â”€ utils/                        # UtilitÃ¡rios
â”‚   â””â”€â”€ delta_spark.py            # Helper para Delta Lake
â”‚
â”œâ”€â”€ lakehouse/                    # Data Lake
â”‚   â”œâ”€â”€ bronze/                   # Dados brutos (JSON particionado)
â”‚   â”œâ”€â”€ silver/                   # Dados curados (Delta Lake)
â”‚   â””â”€â”€ gold/                     # AgregaÃ§Ãµes (Delta Lake)
â”‚
â””â”€â”€ logs/                         # Logs do Airflow
```

## DescriÃ§Ã£o da DAG [breweries_pipeline_dag.py]

<img width="297" height="313" alt="image" src="https://github.com/user-attachments/assets/0d298aac-51a8-4554-b186-54f322c1f7c0" />

<img width="1151" height="302" alt="image" src="https://github.com/user-attachments/assets/d4eeab73-0879-4a18-bd7c-58cdcd223fa7" />

O pipeline Ã© composto por 4 tasks principais encadeadas:

### 1ï¸âƒ£ Bronze Ingestion (`bronze_ingestion`)
**ResponsÃ¡vel por:**
- Extrair dados da API Open Brewery DB com paginaÃ§Ã£o automÃ¡tica (~9,000 cervejarias)
- Persistir dados brutos em formato JSON no lakehouse/bronze
- Particionamento temporal: `year=YYYY/month=MM/day=DD/breweries_TIMESTAMP.json`
- Retornar metadados via XCom: `total_records`, `pages_processed`, `ingestion_path`, `status`

**Tratamento de erros:** Retry atÃ© 3x com backoff exponencial (5min â†’ 10min â†’ 20min)

### 2ï¸âƒ£ Silver Transformation (`silver_transformation`)
**ResponsÃ¡vel por:**
- **Processamento incremental**: consome APENAS o arquivo da ingestÃ£o atual (via `ingestion_path`)
- Limpeza e normalizaÃ§Ã£o de dados (trim, null handling, padronizaÃ§Ã£o)
- Enriquecimento: `full_address`, flags `has_coordinates`, `has_contact`, timestamp `processed_at`
- **ğŸŒ Geocoding automÃ¡tico** (EXTRA): Enriquece coordenadas faltantes via API Nominatim
- **âœ… ValidaÃ§Ã£o geogrÃ¡fica** (EXTRA): Valida coordenadas e marca pontos suspeitos/invÃ¡lidos
- Escrita em Delta Lake com **schema evolution** habilitado para novas colunas
- Particionamento: `country_normalized`, `state`
- CÃ¡lculo de mÃ©tricas de qualidade: completeness rate, coordinate coverage, contact coverage
- Retornar metadados: `output_records`, `distinct_countries`, `distinct_types`, `quality_metrics`, `geocoding_metrics`

**InovaÃ§Ãµes:**
- Processamento incremental evita reprocessamento de histÃ³rico
- Geocoding configurable: `max_geocoding_records` para controlar volume
- Logs detalhados de validaÃ§Ã£o de coordenadas (null island, out of range, wrong country)

### 3ï¸âƒ£ Gold Aggregation (`gold_aggregation`)
**ResponsÃ¡vel por:**
- Consumir dados curados da Silver layer
- **ğŸ“Š Criar tabela completa de breweries** (EXTRA): Dataset nÃ£o-agregado para dashboard
- Criar 6 agregaÃ§Ãµes estratÃ©gicas de negÃ³cio:
  - `by_country`: Total de cervejarias por paÃ­s
  - `by_type`: DistribuiÃ§Ã£o por tipo de cervejaria
  - `by_state`: DistribuiÃ§Ã£o por estado (top 20)
  - `by_type_and_country`: Matriz tipo Ã— paÃ­s
  - `by_type_and_state`: Matriz tipo Ã— estado
  - `summary_statistics`: EstatÃ­sticas consolidadas
- Persistir cada dataset como tabela Delta Lake separada
- OtimizaÃ§Ã£o para consumo analÃ­tico (baixa latÃªncia)

### 4ï¸âƒ£ Validate Pipeline (`validate_pipeline`)
**ResponsÃ¡vel por:**
- Validar integridade dos metadados de todas as camadas
- Verificar status de execuÃ§Ã£o (SUCCESS vs FAILURE)
- Calcular `data_loss_rate` comparando registros Bronze vs Silver
- Gerar relatÃ³rio consolidado com:
  - Status final: SUCCESS/FAILURE
  - MÃ©tricas de cada camada
  - Indicadores de qualidade (paÃ­ses, tipos, cobertura)
  - Taxa de perda de dados (esperado: 0%)

**Callback:** Em caso de falha, aciona `on_failure_callback` para notificaÃ§Ã£o

## Mais Detalhes sobre a DAG

### Data Quality
A validaÃ§Ã£o de qualidade foi implementada em mÃºltiplas camadas:
- **Bronze**: ValidaÃ§Ã£o de schema JSON e total de registros
- **Silver**: MÃ©tricas de completeness, coordinate coverage, contact coverage, contagem de valores Ãºnicos
- **Gold**: ValidaÃ§Ã£o de agregaÃ§Ãµes e consistÃªncia de totais
- **Pipeline**: ValidaÃ§Ã£o end-to-end com cÃ¡lculo de data loss rate

PossÃ­veis evoluÃ§Ãµes: Great Expectations, Soda Core, alertas via Slack/email

### Monitoramento
ImplementaÃ§Ã£o atual:
- **XCom**: Rastreamento de metadados entre tasks
- **Airflow Logs**: Logs estruturados com timestamps e contexto
- **MÃ©tricas de execuÃ§Ã£o**: Duration, records processed, quality metrics

EvoluÃ§Ãµes possÃ­veis:
- IntegraÃ§Ã£o com **Prometheus + Grafana** para dashboards em tempo real
- Alertas proativos via **PagerDuty** ou **Opsgenie**
- Observabilidade com **OpenTelemetry**

### Processamento Incremental
**Problema resolvido:** Silver layer inicialmente processava TODO o histÃ³rico Bronze a cada execuÃ§Ã£o (multiplicaÃ§Ã£o de dados).

**SoluÃ§Ã£o implementada:**
```python
# DAG passa o caminho especÃ­fico da ingestÃ£o
silver.transform_breweries(ingestion_path=bronze_metadata['ingestion_path'])

# Silver layer processa apenas o arquivo especÃ­fico
if ingestion_path:
    df = spark.read.json(ingestion_path)  # âœ… Incremental
else:
    df = spark.read.json(f"{bronze_path}/year=*/month=*/day=*/*.json")  # Full load
```

**Resultado:** 0% data loss, processamento eficiente, sem duplicaÃ§Ã£o

## Arquitetura de Deployment

### Docker Compose (7 serviÃ§os)
- **postgres**: Metadata database (Airflow backend)
- **redis**: Message broker (Celery)
- **scheduler**: Agendador de DAGs
- **worker**: Executor de tasks (CeleryExecutor)
- **webserver**: Interface web (porta 8080)
- **triggerer**: Deferrable operators
- **flower**: Monitoramento Celery (porta 5555)

### Volumes Persistentes
- `./dags` â†’ `/opt/airflow/dags`
- `./logs` â†’ `/opt/airflow/logs`
- `./lakehouse` â†’ `/opt/airflow/lakehouse`
- `./src` â†’ `/opt/airflow/src`
- `./utils` â†’ `/opt/airflow/utils`

## Pontos de Melhoria e PrÃ³ximos Passos

### 1. Escalabilidade e Cloud-Native
**Desafio atual:** Spark rodando em Ãºnico worker do Airflow (limitaÃ§Ã£o de recursos)

**SoluÃ§Ã£o proposta:**
- Migrar para **Kubernetes** (EKS, GKE ou AKS)
- Implementar **Spark Operator** para auto-scaling de Spark executors
- Utilizar **Airflow on K8s** com KubernetesExecutor

**BenefÃ­cios:** Alta disponibilidade, elasticidade, melhor utilizaÃ§Ã£o de recursos

### 2. CI/CD e Infraestrutura como CÃ³digo
**ImplementaÃ§Ãµes sugeridas:**
- **Terraform** para provisionamento de infra (AWS/GCP/Azure)
- **GitHub Actions** ou **GitLab CI** para pipelines CI/CD
- **ArgoCD** para GitOps e deployment automatizado
- **Testes automatizados** em mÃºltiplos ambientes (dev, staging, prod)

**BenefÃ­cios:** FinOps, reprodutibilidade, rollback rÃ¡pido, segregaÃ§Ã£o de ambientes

### 3. SeguranÃ§a e GovernanÃ§a
- **Secrets Management**: Migrar para AWS Secrets Manager ou HashiCorp Vault
- **IAM Roles**: Implementar least privilege access

### 4. OtimizaÃ§Ãµes de Performance
- **Z-Ordering** no Delta Lake para queries otimizadas
- **Data Skipping** com estatÃ­sticas de partiÃ§Ãµes
- **Compaction** automÃ¡tico de small files
- **Caching** de datasets frequentes

### 5. Advanced Analytics
- **Streaming**: Implementar ingestÃ£o em tempo real com Kafka + Spark Streaming
- **Data Quality**: Integrar Great Expectations com alertas automÃ¡ticos

## ğŸ¨ Dashboard Interativo com Streamlit (FUNCIONALIDADE EXTRA)

> **ğŸ“Œ IMPORTANTE:** Esta funcionalidade foi implementada como um **diferencial adicional**, nÃ£o sendo parte dos requisitos originais do case. O objetivo Ã© demonstrar o valor dos dados processados atravÃ©s de visualizaÃ§Ãµes interativas e insights acionÃ¡veis.

Como demonstraÃ§Ã£o adicional das capacidades do pipeline, foi implementado um **dashboard interativo com Streamlit** para visualizaÃ§Ã£o dos dados agregados na camada Gold.

### CaracterÃ­sticas do Dashboard

**ğŸ“Š 5 Abas de AnÃ¡lise:**
1. **ğŸ—ºï¸ Maps** (EXTRA): VisualizaÃ§Ã£o geogrÃ¡fica global com mapas interativos
   - Scatter plot mundial com filtros por paÃ­s e tipo
   - Mapa de densidade por concentraÃ§Ã£o geogrÃ¡fica
   - Filtros dinÃ¢micos de coordenadas vÃ¡lidas
   - Alertas de coordenadas invÃ¡lidas filtradas
   
2. **ğŸŒ Geographic**: DistribuiÃ§Ã£o global de cervejarias
   - VisualizaÃ§Ã£o comparativa (incluindo/excluindo EUA)
   - Top 10 paÃ­ses com treemap hierÃ¡rquico
   
3. **ğŸ·ï¸ Types**: AnÃ¡lise por tipo de cervejaria
   - GrÃ¡ficos de pizza e barras interativos
   - DistribuiÃ§Ã£o percentual
   
4. **ğŸ“ˆ Quality**: MÃ©tricas de qualidade dos dados
   - Gauges interativos para cobertura de coordenadas
   - MÃ©tricas de informaÃ§Ãµes de contato
   - Impacto do geocoding (antes/depois)
   
5. **ğŸ™ï¸ Cities**: AnÃ¡lise por estados
   - Treemap hierÃ¡rquico (paÃ­s â†’ estado â†’ cidade)
   - Top 20 rankings dinÃ¢micos

**ğŸ”§ Stack TÃ©cnico:**
- **Streamlit 1.31.0**: Framework web interativo
- **Plotly 5.18.0**: VisualizaÃ§Ãµes interativas e responsivas (scatter_geo, treemap, gauges)
- **deltalake 0.15.0**: Leitura nativa de Delta Lake sem overhead Java/Spark
- **pandas 2.1.4**: ManipulaÃ§Ã£o de dados

**ğŸ¯ DecisÃµes Arquiteturais:**
- UtilizaÃ§Ã£o da biblioteca `deltalake` Python para leitura direta dos arquivos Delta, evitando a complexidade de inicializar Spark/JVM no container do Streamlit
- Dashboard consome diretamente as tabelas Gold agregadas pelo pipeline Airflow
- Deploy como serviÃ§o adicional no Docker Compose com profile dedicado (`--profile streamlit`)
- Filtros de coordenadas vÃ¡lidas aplicados automaticamente (remove pontos no oceano)

### Como Executar o Dashboard

```bash
# Iniciar todos os serviÃ§os incluindo Streamlit
docker compose --profile streamlit up -d

# Acessar o dashboard
# URL: http://localhost:8501
```

O dashboard se conecta automaticamente aos dados da camada Gold e oferece:
- âœ… VisualizaÃ§Ãµes interativas com zoom, pan e export de imagens
- âœ… Filtros e drill-down para anÃ¡lise detalhada
- âœ… MÃ©tricas de qualidade em tempo real
- âœ… Insights automÃ¡ticos sobre distribuiÃ§Ã£o e cobertura de dados

**ğŸ’¡ BenefÃ­cios:**
- DemonstraÃ§Ã£o visual do valor agregado pelo pipeline
- Interface amigÃ¡vel para stakeholders nÃ£o-tÃ©cnicos
- ValidaÃ§Ã£o imediata da qualidade das agregaÃ§Ãµes Gold
- Base para desenvolvimento de analytics avanÃ§ados

### Parar o Dashboard

```bash
# Parar apenas o Streamlit
docker compose stop streamlit

# Parar todos os serviÃ§os
docker compose --profile streamlit down
```

## Passos para Executar o Projeto

> [!NOTE]
> Projeto desenvolvido e testado em ambiente Linux (Ubuntu/Debian)

### Requisitos
- Docker 20.10+
- Docker Compose 2.0+
- 8GB RAM mÃ­nimo
- 20GB espaÃ§o em disco

### 1. Clonar o RepositÃ³rio
```bash
git clone https://github.com/brulim-almeida/case-breweries.git
cd case-breweries
```

### 2. Configurar VariÃ¡veis de Ambiente
```bash
cp .env.example .env
# Editar .env se necessÃ¡rio (configuraÃ§Ãµes padrÃ£o jÃ¡ funcionam)
```

### 3. Ajustar PermissÃµes (Linux)
```bash
sudo chmod -R 777 ./logs ./lakehouse
```

### 4. Build da Imagem Docker
```bash
docker build -t airflow-breweries:latest .
```

> [!TIP]
> A imagem jÃ¡ inclui OpenJDK 17, PySpark 3.5.0 e Delta Lake 3.1.0

### 5. Iniciar os ServiÃ§os
```bash
docker compose up -d
```

Aguarde ~2 minutos para inicializaÃ§Ã£o completa. Verifique status:
```bash
docker compose ps
```

### 6. Acessar o Airflow Webserver
```
URL: http://localhost:8080
Login: airflow
Senha: airflow
```

### 7. Executar a DAG
1. Na interface web, vÃ¡ em **DAGs**
2. Localize `breweries_pipeline_dag`
3. Ative a DAG (toggle on)
4. Clique em **Trigger DAG** (botÃ£o â–¶ï¸)

### 8. Monitorar ExecuÃ§Ã£o
- **Graph View**: Visualizar dependÃªncias entre tasks
- **Grid View**: HistÃ³rico de execuÃ§Ãµes
- **Logs**: Logs detalhados de cada task
- **Flower**: http://localhost:5555 (monitoramento Celery)

**Logs Esperados de Geocoding (Silver Layer):**
```
GEOCODING ENRICHMENT
================================================================================
BEFORE Geocoding:
  Total records: 9,038
  With coordinates: 6,685 (73.97%)
  Missing coordinates: 2,353 (26.03%)

Processing 1000 addresses...
â±ï¸  Estimated minimum time: ~16.7 minutes (at 1.0s per request)

Progress: 10/100 (10.0%) - Geocoded: 10, Failed: 0 - ETA: ~15.2 min
Progress: 100/1000 (10.0%) - Geocoded: 95, Failed: 5 - ETA: ~14.8 min
...

AFTER Geocoding:
  With coordinates: 7,580 (83.87%)
  Missing coordinates: 1,458 (16.13%)
  
Enrichment: +895 new coordinates (38.0% improvement)
Success rate: 89.5%
```

**Logs Esperados de ValidaÃ§Ã£o de Coordenadas:**
```
Validating geographic coordinates...
Coordinate validation results:
  Total with coordinates: 7,580
  Valid coordinates: 7,340 (96.83%)
  Invalid/Suspicious: 240 (3.17%)
  
Validation failures breakdown:
  - Null Island (0,0): 8
  - Out of range: 2
  - Wrong country/region: 230
```

### 9. Validar Resultados
```bash
# Verificar dados Bronze
ls -lh lakehouse/bronze/breweries/year=*/month=*/day=*/

# Verificar dados Silver (Delta Lake)
ls -lh lakehouse/silver/breweries/_delta_log/

# Verificar agregaÃ§Ãµes Gold
ls -lh lakehouse/gold/breweries/
```

### 10. Parar os ServiÃ§os
```bash
docker compose down  # Para os serviÃ§os
docker compose down -v  # Para e remove volumes (reset completo)
```

## Estrutura de Dados

### Bronze Layer
```json
{
  "id": "5128df48-79fc-4f0f-8b52-d06be54d0cec",
  "name": "Foo Bar Brewery",
  "brewery_type": "micro",
  "address_1": "1234 Main St",
  "city": "San Francisco",
  "state": "California",
  "postal_code": "94102",
  "country": "United States",
  "longitude": "-122.419906",
  "latitude": "37.7749",
  "phone": "4155551234",
  "website_url": "http://foobarbrewery.com"
}
```

### Silver Layer (Delta Lake)
Adiciona campos enriquecidos:
- `full_address`: String concatenada completa
- `country_normalized`: PaÃ­s normalizado
- `brewery_type_normalized`: Tipo normalizado
- `has_coordinates`: Boolean (latitude e longitude preenchidas)
- `has_contact`: Boolean (phone ou website preenchido)
- `is_complete`: Boolean (dados completos)
- `coordinates_valid`: Boolean (EXTRA - validaÃ§Ã£o geogrÃ¡fica)
- `silver_processed_at`: Timestamp de processamento
- `processing_date`, `processing_year`, `processing_month`: Campos temporais

### Gold Layer Aggregations
- **breweries** (EXTRA): Tabela completa nÃ£o-agregada para dashboard
- **by_country**: `country`, `total_breweries`
- **by_type**: `brewery_type`, `total_breweries`
- **by_state**: `country`, `state`, `total_breweries`
- **by_type_and_country**: `brewery_type`, `country`, `total_breweries`
- **by_type_and_state**: `brewery_type`, `state`, `total_breweries`
- **summary_statistics**: EstatÃ­sticas consolidadas de qualidade e cobertura

## Testes

Executar testes unitÃ¡rios:
```bash
# Dentro do container Airflow
docker compose exec airflow-webserver pytest tests/ -v

# Com coverage
docker compose exec airflow-webserver pytest tests/ --cov=src --cov-report=html
```

## Troubleshooting

### Erro: "No space left on device"
```bash
docker system prune -a --volumes
```

### Erro: "Port 8080 already in use"
Editar `docker-compose.yaml` e alterar porta do webserver

### DAG nÃ£o aparece na interface
```bash
# Verificar logs do scheduler
docker compose logs airflow-scheduler -f

# Validar sintaxe da DAG
docker compose exec airflow-webserver python /opt/airflow/dags/breweries_pipeline_dag.py
```

### Tasks falhando com erro de memÃ³ria
Aumentar recursos do Docker Desktop ou reduzir `spark.executor.memory` em `utils/delta_spark.py`

## ConclusÃ£o & Agradecimentos

Este projeto demonstra a implementaÃ§Ã£o completa de um Data Lake moderno utilizando as melhores prÃ¡ticas de engenharia de dados:

**âœ… Requisitos do Case (Implementados):**
- Arquitetura Medallion para organizaÃ§Ã£o e qualidade
- Processamento incremental para eficiÃªncia
- OrquestraÃ§Ã£o robusta com Airflow
- ACID transactions com Delta Lake
- CÃ³digo modular, testÃ¡vel e documentado
- Deploy containerizado e reprodutÃ­vel

**ğŸš€ Funcionalidades Extras (AlÃ©m do Case):**
- **Dashboard Streamlit** com 5 abas de anÃ¡lise e visualizaÃ§Ãµes interativas
- **Geocoding automÃ¡tico** para enriquecer 26% das cervejarias sem coordenadas
- **ValidaÃ§Ã£o geogrÃ¡fica** para identificar e filtrar coordenadas invÃ¡lidas
- **Tabela completa na Gold** para anÃ¡lises exploratÃ³rias
- **MÃ©tricas avanÃ§adas** de data quality e performance

O case oferece uma base sÃ³lida para evoluÃ§Ãµes futuras em cloud, ML pipelines e analytics avanÃ§ado, enquanto as funcionalidades extras demonstram capacidade de ir alÃ©m dos requisitos e agregar valor ao produto final.

AgradeÃ§o pela oportunidade e estou disponÃ­vel para qualquer esclarecimento!

---

**Autor:** [Bruno Lima](https://www.linkedin.com/in/brulimalmeida/)  
**RepositÃ³rio:** [case-breweries](https://github.com/brulim-almeida/case-breweries)  
