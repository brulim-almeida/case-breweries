# Case Breweries Data Lake

O desafio deste case foi desenvolver um pipeline de dados robusto para extrair, processar e armazenar informa√ß√µes de cervejarias a partir da API Open Brewery DB. O pipeline segue a arquitetura Medallion (Bronze, Silver e Gold) implementada com Apache Airflow, PySpark e Delta Lake.

<img width="935" height="418" alt="image" src="https://github.com/user-attachments/assets/e75faccd-fc85-47a8-84f8-f6b73fb8ccbb" />


> üíæ Arquitetura da Pipeline de Dados

## Resumo dos Principais Conceitos e Tecnologias Utilizadas

* **Pipeline orquestrado no Apache Airflow** com TaskFlow API
* **Airflow rodando em containers Docker** com CeleryExecutor para processamento distribu√≠do
* **Processamento via PySpark 3.5.0** com suporte a Delta Lake 3.1.0
* **Arquitetura Medallion** (Bronze ‚Üí Silver ‚Üí Gold) para organiza√ß√£o e qualidade dos dados
* **Processamento incremental** na Silver layer para evitar reprocessamento de dados hist√≥ricos
* **Delta Lake** para ACID transactions e versionamento de dados
* **Boas pr√°ticas de engenharia**: c√≥digo modular, documentado e test√°vel
* **Data Quality** integrado com valida√ß√µes e m√©tricas de qualidade em cada camada
* **XCom** para comunica√ß√£o entre tasks e rastreamento de metadados

---

## üéØ Funcionalidades Extras Implementadas (Al√©m do Case Original)

Este projeto vai al√©m dos requisitos b√°sicos do case, incluindo funcionalidades avan√ßadas que agregam valor significativo ao pipeline:

### 1. üé® Dashboard Interativo com Streamlit
**Por que foi adicionado:** Demonstrar o valor dos dados processados atrav√©s de visualiza√ß√µes interativas e acess√≠veis para stakeholders n√£o-t√©cnicos.

**Funcionalidades:**
- 5 abas de an√°lise (Maps, Geographic, Types, Quality, Cities)
- Visualiza√ß√µes interativas com Plotly (mapas, treemaps, gauges)
- M√©tricas de qualidade em tempo real
- Filtros din√¢micos por pa√≠s, tipo e regi√£o
- Leitura nativa de Delta Lake sem overhead Spark

### 2. üåç Geocoding Autom√°tico para Coordenadas Faltantes
**Por que foi adicionado:** ~26% das cervejarias n√£o possuem coordenadas na API, limitando an√°lises geogr√°ficas. A solu√ß√£o enriquece automaticamente esses dados.

**Funcionalidades:**
- Integra√ß√£o com API Nominatim (OpenStreetMap)
- Geocoding inteligente com estrat√©gia de fallback
- Rate limiting respeitando limites da API (1 req/seg)
- M√©tricas detalhadas: taxa de sucesso, cobertura, performance
- Processamento batch configur√°vel (100-1000 registros por execu√ß√£o)

**Resultados esperados:**
- Melhoria de cobertura geogr√°fica de ~74% para ~85%+
- Viabiliza√ß√£o de an√°lises espaciais completas
- Logs detalhados de sucesso/falha para auditoria

### 3. ‚úÖ Valida√ß√£o Geogr√°fica de Coordenadas
**Por que foi adicionado:** Algumas coordenadas da API (e do geocoding) s√£o incorretas, resultando em pontos no oceano ou pa√≠ses errados.

**Valida√ß√µes implementadas:**
- Range check: latitude (-90 a 90), longitude (-180 a 180)
- Detec√ß√£o de "Null Island" (0,0) - erro comum de geocoding
- Consist√™ncia geogr√°fica: verifica se coordenadas batem com pa√≠s informado
- Bounding boxes para 13 pa√≠ses principais (USA, UK, Brasil, Alemanha, etc.)
- Coluna `coordinates_valid` para filtragem autom√°tica

**Benef√≠cios:**
- Mapas limpos sem pontos suspeitos no oceano
- Maior confiabilidade em an√°lises geogr√°ficas
- Identifica√ß√£o de problemas de qualidade para corre√ß√£o

### 4. üìä Tabela Completa de Breweries na Gold Layer
**Por que foi adicionado:** O dashboard precisa acessar dados individuais de cervejarias (n√£o apenas agrega√ß√µes).

**Implementa√ß√£o:**
- Tabela `breweries` completa (n√£o particionada) na Gold layer
- Otimizada para consultas anal√≠ticas r√°pidas
- Inclui todas as colunas enriched da Silver + valida√ß√µes
- Base para an√°lises explorat√≥rias e drill-down

### 5. üìà M√©tricas Avan√ßadas de Data Quality
**Al√©m das m√©tricas b√°sicas, foram implementadas:**
- Cobertura de coordenadas (antes/depois do geocoding)
- Taxa de melhoria de qualidade
- Breakdown de falhas de valida√ß√£o
- Performance de geocoding (registros/segundo)
- Taxa de perda de dados entre camadas (data loss rate)

### 6. üîç Great Expectations - Valida√ß√£o Automatizada de Qualidade
**Por que foi adicionado:** Data quality √© cr√≠tico em produ√ß√£o. Great Expectations automatiza valida√ß√£o de dados e gera documenta√ß√£o interativa.

**Funcionalidades:**
- **Valida√ß√£o em 3 camadas:** Bronze, Silver e Gold com expectations espec√≠ficas
- **Anomaly Detection:** Detecta varia√ß√µes de volume >20% entre execu√ß√µes
- **Data Docs HTML:** Documenta√ß√£o interativa com gr√°ficos e profiling estat√≠stico
- **28+ Expectations:** Schema, uniqueness, completeness, ranges, domain validation
- **Integrated no Airflow:** Valida√ß√£o autom√°tica ap√≥s cada camada do pipeline

**Valida√ß√µes por Camada:**
- **Bronze:** Schema API, IDs √∫nicos, volume esperado (5k-50k), tipos conhecidos, coordinate ranges
- **Silver:** Data loss <5%, pa√≠s normalizado 100%, 85%+ coords v√°lidas, Null Island detection
- **Gold:** Agrega√ß√µes n√£o vazias, counts positivos, USA/micro presentes, integridade matem√°tica

**Estat√≠sticas Rastreadas:**
- Success rate por expectation (% de aprova√ß√£o)
- Data retention rate (Bronze‚ÜíSilver: 99.4%+)
- Coordinate coverage (Bronze: 74% ‚Üí Silver: 86%+)
- Geocoding success rate (~85% de sucesso)
- Validation execution time por layer

**Benef√≠cios:**
- Detecta problemas antes de impactar an√°lises
- Documenta√ß√£o autom√°tica de qualidade de dados
- Rastreamento de qualidade ao longo do tempo
- Padr√£o da ind√∫stria (Netflix, Uber, Airbnb)

üìÑ **Documenta√ß√£o completa:** [GREAT_EXPECTATIONS_GUIDE.md](GREAT_EXPECTATIONS_GUIDE.md)

### 7. üìä Pipeline Metrics Dashboard
**Por que foi adicionado:** Monitoramento e observabilidade s√£o essenciais para opera√ß√£o em produ√ß√£o.

**Funcionalidades:**
- **Aba dedicada no Streamlit** para visualizar m√©tricas de execu√ß√£o
- **Tempos de execu√ß√£o** detalhados por camada (Bronze, Silver, Gold)
- **Hist√≥rico de execu√ß√µes** com gr√°ficos de tend√™ncia (√∫ltimas 20 runs)
- **M√©tricas de qualidade** integradas com Great Expectations
- **Fluxo de dados visual** (Sankey diagram) mostrando reten√ß√£o de dados
- **Estat√≠sticas de enrichment** (geocoding coverage, valida√ß√£o geogr√°fica)

**M√©tricas Exibidas:**
- ‚è±Ô∏è Execution times: Bronze, Silver, Gold e total
- üìä Data volumes: Records ingested, transformed, aggregations created
- üìâ Data loss rate: Perda Bronze ‚Üí Silver
- üîç Validation results: Success rate por camada (Great Expectations)
- üåç Enrichment stats: Coordinate coverage, valid coords, geocoded rate
- üìà Historical trends: Volume e tempo de execu√ß√£o ao longo do tempo

**Benef√≠cios:**
- Visibilidade completa do pipeline em tempo real
- Identifica√ß√£o de bottlenecks de performance
- Rastreamento de SLA e execution times
- Debugging facilitado com hist√≥rico de execu√ß√µes
- Demonstra maturidade operacional

üìÑ **Metadados salvos em:** `lakehouse/metadata/pipeline_runs.json`
- Breakdown de falhas de valida√ß√£o
- Performance de geocoding (registros/segundo)
- Taxa de perda de dados entre camadas (data loss rate)

---

## Estrutura de Diret√≥rios e Arquivos

```
case-breweries/
‚îú‚îÄ‚îÄ .env                          # Vari√°veis de ambiente
‚îú‚îÄ‚îÄ .env.example                  # Template de configura√ß√£o
‚îú‚îÄ‚îÄ .gitignore                    # Git ignore rules
‚îú‚îÄ‚îÄ Dockerfile                    # Imagem customizada Airflow + PySpark
‚îú‚îÄ‚îÄ docker-compose.yaml           # Orquestra√ß√£o completa (8 servi√ßos)
‚îú‚îÄ‚îÄ pytest.ini                    # Configura√ß√£o de testes
‚îú‚îÄ‚îÄ requirements.txt              # Depend√™ncias Python
‚îÇ
‚îú‚îÄ‚îÄ airflow/                      # Configura√ß√µes Airflow
‚îÇ   ‚îî‚îÄ‚îÄ README.md                 # Documenta√ß√£o de setup
‚îÇ
‚îú‚îÄ‚îÄ dags/                         # DAGs do Airflow
‚îÇ   ‚îî‚îÄ‚îÄ breweries_pipeline_dag.py # Pipeline principal
‚îÇ
‚îú‚îÄ‚îÄ dashboards/                   # üé® Dashboard Streamlit (EXTRA)
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py          # App interativo com visualiza√ß√µes
‚îÇ
‚îú‚îÄ‚îÄ src/                          # C√≥digo-fonte principal
‚îÇ   ‚îú‚îÄ‚îÄ api/                      # Cliente API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ brewery_client.py    # Integra√ß√£o com Open Brewery DB
‚îÇ   ‚îú‚îÄ‚îÄ config/                   # Configura√ß√µes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py           # Settings centralizados
‚îÇ   ‚îú‚îÄ‚îÄ enrichment/               # Enriquecimento de dados (EXTRA)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ geocoding.py          # Geocoding com Nominatim API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_geocoding.py    # Testes de geocoding
‚îÇ   ‚îî‚îÄ‚îÄ layers/                   # Camadas Medallion
‚îÇ       ‚îú‚îÄ‚îÄ bronze_layer.py       # Ingest√£o de dados brutos
‚îÇ       ‚îú‚îÄ‚îÄ silver_layer.py       # Transforma√ß√£o + Geocoding + Valida√ß√£o
‚îÇ       ‚îî‚îÄ‚îÄ gold_layer.py         # Agrega√ß√µes + Tabela completa
‚îÇ
‚îú‚îÄ‚îÄ tests/                        # Testes unit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ test_bronze_layer.py
‚îÇ   ‚îú‚îÄ‚îÄ test_silver_layer.py
‚îÇ   ‚îî‚îÄ‚îÄ test_gold_layer.py
‚îÇ
‚îú‚îÄ‚îÄ utils/                        # Utilit√°rios
‚îÇ   ‚îî‚îÄ‚îÄ delta_spark.py            # Helper para Delta Lake
‚îÇ
‚îú‚îÄ‚îÄ lakehouse/                    # Data Lake
‚îÇ   ‚îú‚îÄ‚îÄ bronze/                   # Dados brutos (JSON particionado)
‚îÇ   ‚îú‚îÄ‚îÄ silver/                   # Dados curados (Delta Lake)
‚îÇ   ‚îî‚îÄ‚îÄ gold/                     # Agrega√ß√µes (Delta Lake)
‚îÇ
‚îî‚îÄ‚îÄ logs/                         # Logs do Airflow
```

## Descri√ß√£o da DAG [breweries_pipeline_dag.py]

<img width="297" height="313" alt="image" src="https://github.com/user-attachments/assets/0d298aac-51a8-4554-b186-54f322c1f7c0" />

<img width="1151" height="302" alt="image" src="https://github.com/user-attachments/assets/d4eeab73-0879-4a18-bd7c-58cdcd223fa7" />

O pipeline √© composto por 4 tasks principais encadeadas:

### 1Ô∏è‚É£ Bronze Ingestion (`bronze_ingestion`)
**Respons√°vel por:**
- Extrair dados da API Open Brewery DB com pagina√ß√£o autom√°tica (~9,000 cervejarias)
- Persistir dados brutos em formato JSON no lakehouse/bronze
- Particionamento temporal: `year=YYYY/month=MM/day=DD/breweries_TIMESTAMP.json`
- Retornar metadados via XCom: `total_records`, `pages_processed`, `ingestion_path`, `status`

**Tratamento de erros:** Retry at√© 3x com backoff exponencial (5min ‚Üí 10min ‚Üí 20min)

### 2Ô∏è‚É£ Silver Transformation (`silver_transformation`)
**Respons√°vel por:**
- **Processamento incremental**: consome APENAS o arquivo da ingest√£o atual (via `ingestion_path`)
- Limpeza e normaliza√ß√£o de dados (trim, null handling, padroniza√ß√£o)
- Enriquecimento: `full_address`, flags `has_coordinates`, `has_contact`, timestamp `processed_at`
- **üåç Geocoding autom√°tico** (EXTRA): Enriquece coordenadas faltantes via API Nominatim
- **‚úÖ Valida√ß√£o geogr√°fica** (EXTRA): Valida coordenadas e marca pontos suspeitos/inv√°lidos
- Escrita em Delta Lake com **schema evolution** habilitado para novas colunas
- Particionamento: `country_normalized`, `state`
- C√°lculo de m√©tricas de qualidade: completeness rate, coordinate coverage, contact coverage
- Retornar metadados: `output_records`, `distinct_countries`, `distinct_types`, `quality_metrics`, `geocoding_metrics`

**Inova√ß√µes:**
- Processamento incremental evita reprocessamento de hist√≥rico
- Geocoding configurable: `max_geocoding_records` para controlar volume
- Logs detalhados de valida√ß√£o de coordenadas (null island, out of range, wrong country)

### 3Ô∏è‚É£ Gold Aggregation (`gold_aggregation`)
**Respons√°vel por:**
- Consumir dados curados da Silver layer
- **üìä Criar tabela completa de breweries** (EXTRA): Dataset n√£o-agregado para dashboard
- Criar 6 agrega√ß√µes estrat√©gicas de neg√≥cio:
  - `by_country`: Total de cervejarias por pa√≠s
  - `by_type`: Distribui√ß√£o por tipo de cervejaria
  - `by_state`: Distribui√ß√£o por estado (top 20)
  - `by_type_and_country`: Matriz tipo √ó pa√≠s
  - `by_type_and_state`: Matriz tipo √ó estado
  - `summary_statistics`: Estat√≠sticas consolidadas
- Persistir cada dataset como tabela Delta Lake separada
- Otimiza√ß√£o para consumo anal√≠tico (baixa lat√™ncia)

### 4Ô∏è‚É£ Validate Pipeline (`validate_pipeline`)
**Respons√°vel por:**
- Validar integridade dos metadados de todas as camadas
- Verificar status de execu√ß√£o (SUCCESS vs FAILURE)
- Calcular `data_loss_rate` comparando registros Bronze vs Silver
- Gerar relat√≥rio consolidado com:
  - Status final: SUCCESS/FAILURE
  - M√©tricas de cada camada
  - Indicadores de qualidade (pa√≠ses, tipos, cobertura)
  - Taxa de perda de dados (esperado: 0%)

**Callback:** Em caso de falha, aciona `on_failure_callback` para notifica√ß√£o

## Mais Detalhes sobre a DAG

### Data Quality
A valida√ß√£o de qualidade foi implementada em m√∫ltiplas camadas:
- **Bronze**: Valida√ß√£o de schema JSON e total de registros
- **Silver**: M√©tricas de completeness, coordinate coverage, contact coverage, contagem de valores √∫nicos
- **Gold**: Valida√ß√£o de agrega√ß√µes e consist√™ncia de totais
- **Pipeline**: Valida√ß√£o end-to-end com c√°lculo de data loss rate

Poss√≠veis evolu√ß√µes: Great Expectations, Soda Core, alertas via Slack/email

### Monitoramento
Implementa√ß√£o atual:
- **XCom**: Rastreamento de metadados entre tasks
- **Airflow Logs**: Logs estruturados com timestamps e contexto
- **M√©tricas de execu√ß√£o**: Duration, records processed, quality metrics

Evolu√ß√µes poss√≠veis:
- Integra√ß√£o com **Prometheus + Grafana** para dashboards em tempo real
- Alertas proativos via **PagerDuty** ou **Opsgenie**
- Observabilidade com **OpenTelemetry**

### Processamento Incremental
**Problema resolvido:** Silver layer inicialmente processava TODO o hist√≥rico Bronze a cada execu√ß√£o (multiplica√ß√£o de dados).

**Solu√ß√£o implementada:**
```python
# DAG passa o caminho espec√≠fico da ingest√£o
silver.transform_breweries(ingestion_path=bronze_metadata['ingestion_path'])

# Silver layer processa apenas o arquivo espec√≠fico
if ingestion_path:
    df = spark.read.json(ingestion_path)  # ‚úÖ Incremental
else:
    df = spark.read.json(f"{bronze_path}/year=*/month=*/day=*/*.json")  # Full load
```

**Resultado:** 0% data loss, processamento eficiente, sem duplica√ß√£o

## Arquitetura de Deployment

### Docker Compose (7 servi√ßos)
- **postgres**: Metadata database (Airflow backend)
- **redis**: Message broker (Celery)
- **scheduler**: Agendador de DAGs
- **worker**: Executor de tasks (CeleryExecutor)
- **webserver**: Interface web (porta 8080)
- **triggerer**: Deferrable operators
- **flower**: Monitoramento Celery (porta 5555)

### Volumes Persistentes
- `./dags` ‚Üí `/opt/airflow/dags`
- `./logs` ‚Üí `/opt/airflow/logs`
- `./lakehouse` ‚Üí `/opt/airflow/lakehouse`
- `./src` ‚Üí `/opt/airflow/src`
- `./utils` ‚Üí `/opt/airflow/utils`

## Pontos de Melhoria e Pr√≥ximos Passos

### 1. Escalabilidade e Cloud-Native
**Desafio atual:** Spark rodando em √∫nico worker do Airflow (limita√ß√£o de recursos)

**Solu√ß√£o proposta:**
- Migrar para **Kubernetes** (EKS, GKE ou AKS)
- Implementar **Spark Operator** para auto-scaling de Spark executors
- Utilizar **Airflow on K8s** com KubernetesExecutor

**Benef√≠cios:** Alta disponibilidade, elasticidade, melhor utiliza√ß√£o de recursos

### 2. CI/CD e Infraestrutura como C√≥digo
**Implementa√ß√µes sugeridas:**
- **Terraform** para provisionamento de infra (AWS/GCP/Azure)
- **GitHub Actions** ou **GitLab CI** para pipelines CI/CD
- **ArgoCD** para GitOps e deployment automatizado
- **Testes automatizados** em m√∫ltiplos ambientes (dev, staging, prod)

**Benef√≠cios:** FinOps, reprodutibilidade, rollback r√°pido, segrega√ß√£o de ambientes

### 3. Seguran√ßa e Governan√ßa
- **Secrets Management**: Migrar para AWS Secrets Manager ou HashiCorp Vault
- **IAM Roles**: Implementar least privilege access

### 4. Otimiza√ß√µes de Performance
- **Z-Ordering** no Delta Lake para queries otimizadas
- **Data Skipping** com estat√≠sticas de parti√ß√µes
- **Compaction** autom√°tico de small files
- **Caching** de datasets frequentes

### 5. Advanced Analytics
- **Streaming**: Implementar ingest√£o em tempo real com Kafka + Spark Streaming
- **Data Quality**: Integrar Great Expectations com alertas autom√°ticos

## üé® Dashboard Interativo com Streamlit (FUNCIONALIDADE EXTRA)

> **üìå IMPORTANTE:** Esta funcionalidade foi implementada como um **diferencial adicional**, n√£o sendo parte dos requisitos originais do case. O objetivo √© demonstrar o valor dos dados processados atrav√©s de visualiza√ß√µes interativas e insights acion√°veis.

Como demonstra√ß√£o adicional das capacidades do pipeline, foi implementado um **dashboard interativo com Streamlit** para visualiza√ß√£o dos dados agregados na camada Gold.

### Caracter√≠sticas do Dashboard

**üìä 5 Abas de An√°lise:**
1. **üó∫Ô∏è Maps** (EXTRA): Visualiza√ß√£o geogr√°fica global com mapas interativos
   - Scatter plot mundial com filtros por pa√≠s e tipo
   - Mapa de densidade por concentra√ß√£o geogr√°fica
   - Filtros din√¢micos de coordenadas v√°lidas
   - Alertas de coordenadas inv√°lidas filtradas
   
2. **üåç Geographic**: Distribui√ß√£o global de cervejarias
   - Visualiza√ß√£o comparativa (incluindo/excluindo EUA)
   - Top 10 pa√≠ses com treemap hier√°rquico
   
3. **üè∑Ô∏è Types**: An√°lise por tipo de cervejaria
   - Gr√°ficos de pizza e barras interativos
   - Distribui√ß√£o percentual
   
4. **üìà Quality**: M√©tricas de qualidade dos dados
   - Gauges interativos para cobertura de coordenadas
   - M√©tricas de informa√ß√µes de contato
   - Impacto do geocoding (antes/depois)
   
5. **üèôÔ∏è Cities**: An√°lise por estados
   - Treemap hier√°rquico (pa√≠s ‚Üí estado ‚Üí cidade)
   - Top 20 rankings din√¢micos

**üîß Stack T√©cnico:**
- **Streamlit 1.31.0**: Framework web interativo
- **Plotly 5.18.0**: Visualiza√ß√µes interativas e responsivas (scatter_geo, treemap, gauges)
- **deltalake 0.15.0**: Leitura nativa de Delta Lake sem overhead Java/Spark
- **pandas 2.1.4**: Manipula√ß√£o de dados

**üéØ Decis√µes Arquiteturais:**
- Utiliza√ß√£o da biblioteca `deltalake` Python para leitura direta dos arquivos Delta, evitando a complexidade de inicializar Spark/JVM no container do Streamlit
- Dashboard consome diretamente as tabelas Gold agregadas pelo pipeline Airflow
- Deploy como servi√ßo adicional no Docker Compose com profile dedicado (`--profile streamlit`)
- Filtros de coordenadas v√°lidas aplicados automaticamente (remove pontos no oceano)

### Como Executar o Dashboard

```bash
# Iniciar todos os servi√ßos incluindo Streamlit
docker compose --profile streamlit up -d

# Acessar o dashboard
# URL: http://localhost:8501
```

O dashboard se conecta automaticamente aos dados da camada Gold e oferece:
- ‚úÖ Visualiza√ß√µes interativas com zoom, pan e export de imagens
- ‚úÖ Filtros e drill-down para an√°lise detalhada
- ‚úÖ M√©tricas de qualidade em tempo real
- ‚úÖ Insights autom√°ticos sobre distribui√ß√£o e cobertura de dados

**üí° Benef√≠cios:**
- Demonstra√ß√£o visual do valor agregado pelo pipeline
- Interface amig√°vel para stakeholders n√£o-t√©cnicos
- Valida√ß√£o imediata da qualidade das agrega√ß√µes Gold
- Base para desenvolvimento de analytics avan√ßados

### Parar o Dashboard

```bash
# Parar apenas o Streamlit
docker compose stop streamlit

# Parar todos os servi√ßos
docker compose --profile streamlit down
```

## Passos para Executar o Projeto

> [!NOTE]
> Projeto desenvolvido e testado em ambiente Linux (Ubuntu/Debian)

### Requisitos
- Docker 20.10+
- Docker Compose 2.0+
- 8GB RAM m√≠nimo
- 20GB espa√ßo em disco

### 1. Clonar o Reposit√≥rio
```bash
git clone https://github.com/brulim-almeida/case-breweries.git
cd case-breweries
```

### 2. Configurar Vari√°veis de Ambiente
```bash
cp .env.example .env
# Editar .env se necess√°rio (configura√ß√µes padr√£o j√° funcionam)
```

### 3. Ajustar Permiss√µes (Linux)
```bash
sudo chmod -R 777 ./logs ./lakehouse
```

### 4. Build da Imagem Docker
```bash
docker build -t airflow-breweries:latest .
```

> [!TIP]
> A imagem j√° inclui OpenJDK 17, PySpark 3.5.0 e Delta Lake 3.1.0

### 5. Iniciar os Servi√ßos
```bash
docker compose up -d
```

Aguarde ~2 minutos para inicializa√ß√£o completa. Verifique status:
```bash
docker compose ps
```

### 6. Acessar o Airflow Webserver
```
URL: http://localhost:8080
Login: airflow
Senha: airflow
```

### 7. Executar a DAG
1. Na interface web, v√° em **DAGs**
2. Localize `breweries_pipeline_dag`
3. Ative a DAG (toggle on)
4. Clique em **Trigger DAG** (bot√£o ‚ñ∂Ô∏è)

### 8. Monitorar Execu√ß√£o
- **Graph View**: Visualizar depend√™ncias entre tasks
- **Grid View**: Hist√≥rico de execu√ß√µes
- **Logs**: Logs detalhados de cada task
- **Flower**: http://localhost:5555 (monitoramento Celery)

**Logs Esperados de Geocoding (Silver Layer):**
```
GEOCODING ENRICHMENT
================================================================================
BEFORE Geocoding:
  Total records: 9,038
  With coordinates: 6,685 (73.97%)
  Missing coordinates: 2,353 (26.03%)

Processing 1000 addresses...
‚è±Ô∏è  Estimated minimum time: ~16.7 minutes (at 1.0s per request)

Progress: 10/100 (10.0%) - Geocoded: 10, Failed: 0 - ETA: ~15.2 min
Progress: 100/1000 (10.0%) - Geocoded: 95, Failed: 5 - ETA: ~14.8 min
...

AFTER Geocoding:
  With coordinates: 7,580 (83.87%)
  Missing coordinates: 1,458 (16.13%)
  
Enrichment: +895 new coordinates (38.0% improvement)
Success rate: 89.5%
```

**Logs Esperados de Valida√ß√£o de Coordenadas:**
```
Validating geographic coordinates...
Coordinate validation results:
  Total with coordinates: 7,580
  Valid coordinates: 7,340 (96.83%)
  Invalid/Suspicious: 240 (3.17%)
  
Validation failures breakdown:
  - Null Island (0,0): 8
  - Out of range: 2
  - Wrong country/region: 230
```

### 9. Validar Resultados
```bash
# Verificar dados Bronze
ls -lh lakehouse/bronze/breweries/year=*/month=*/day=*/

# Verificar dados Silver (Delta Lake)
ls -lh lakehouse/silver/breweries/_delta_log/

# Verificar agrega√ß√µes Gold
ls -lh lakehouse/gold/breweries/
```

### 10. Parar os Servi√ßos
```bash
docker compose down  # Para os servi√ßos
docker compose down -v  # Para e remove volumes (reset completo)
```

## Estrutura de Dados

### Bronze Layer
```json
{
  "id": "5128df48-79fc-4f0f-8b52-d06be54d0cec",
  "name": "Foo Bar Brewery",
  "brewery_type": "micro",
  "address_1": "1234 Main St",
  "city": "San Francisco",
  "state": "California",
  "postal_code": "94102",
  "country": "United States",
  "longitude": "-122.419906",
  "latitude": "37.7749",
  "phone": "4155551234",
  "website_url": "http://foobarbrewery.com"
}
```

### Silver Layer (Delta Lake)
Adiciona campos enriquecidos:
- `full_address`: String concatenada completa
- `country_normalized`: Pa√≠s normalizado
- `brewery_type_normalized`: Tipo normalizado
- `has_coordinates`: Boolean (latitude e longitude preenchidas)
- `has_contact`: Boolean (phone ou website preenchido)
- `is_complete`: Boolean (dados completos)
- `coordinates_valid`: Boolean (EXTRA - valida√ß√£o geogr√°fica)
- `silver_processed_at`: Timestamp de processamento
- `processing_date`, `processing_year`, `processing_month`: Campos temporais

### Gold Layer Aggregations
- **breweries** (EXTRA): Tabela completa n√£o-agregada para dashboard
- **by_country**: `country`, `total_breweries`
- **by_type**: `brewery_type`, `total_breweries`
- **by_state**: `country`, `state`, `total_breweries`
- **by_type_and_country**: `brewery_type`, `country`, `total_breweries`
- **by_type_and_state**: `brewery_type`, `state`, `total_breweries`
- **summary_statistics**: Estat√≠sticas consolidadas de qualidade e cobertura

## Testes

Executar testes unit√°rios:
```bash
# Dentro do container Airflow
docker compose exec airflow-webserver pytest tests/ -v

# Com coverage
docker compose exec airflow-webserver pytest tests/ --cov=src --cov-report=html
```

## Troubleshooting

### Erro: "No space left on device"
```bash
docker system prune -a --volumes
```

### Erro: "Port 8080 already in use"
Editar `docker-compose.yaml` e alterar porta do webserver

### DAG n√£o aparece na interface
```bash
# Verificar logs do scheduler
docker compose logs airflow-scheduler -f

# Validar sintaxe da DAG
docker compose exec airflow-webserver python /opt/airflow/dags/breweries_pipeline_dag.py
```

### Tasks falhando com erro de mem√≥ria
Aumentar recursos do Docker Desktop ou reduzir `spark.executor.memory` em `utils/delta_spark.py`

## Conclus√£o & Agradecimentos

Este projeto demonstra a implementa√ß√£o completa de um Data Lake moderno utilizando as melhores pr√°ticas de engenharia de dados:

**‚úÖ Requisitos do Case (Implementados):**
- Arquitetura Medallion para organiza√ß√£o e qualidade
- Processamento incremental para efici√™ncia
- Orquestra√ß√£o robusta com Airflow
- ACID transactions com Delta Lake
- C√≥digo modular, test√°vel e documentado
- Deploy containerizado e reprodut√≠vel

**üöÄ Funcionalidades Extras (Al√©m do Case):**
- **Dashboard Streamlit** com 5 abas de an√°lise e visualiza√ß√µes interativas
- **Geocoding autom√°tico** para enriquecer 26% das cervejarias sem coordenadas
- **Valida√ß√£o geogr√°fica** para identificar e filtrar coordenadas inv√°lidas
- **Tabela completa na Gold** para an√°lises explorat√≥rias
- **M√©tricas avan√ßadas** de data quality e performance

O case oferece uma base s√≥lida para evolu√ß√µes futuras em cloud, ML pipelines e analytics avan√ßado, enquanto as funcionalidades extras demonstram capacidade de ir al√©m dos requisitos e agregar valor ao produto final.

Agrade√ßo pela oportunidade e estou dispon√≠vel para qualquer esclarecimento!

---

**Autor:** [Bruno Lima](https://www.linkedin.com/in/brulimalmeida/)  
**Reposit√≥rio:** [case-breweries](https://github.com/brulim-almeida/case-breweries)  
